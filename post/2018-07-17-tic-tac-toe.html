<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@_ahmedshariff_"/><meta name="twitter:creator" content="@_ahmedshariff_"/><meta property="og:url" content="https://shariff-faleel.com/"/><meta property="og:type" content="website"/><meta property="og:locale" content="en_CA"/><meta property="og:site_name" content="Personal website of Shariff Faleel"/><title>Teaching a computer to play Tic-Tac-Toe.</title><meta name="robots" content="index,follow"/><meta name="description" content="Teaching a computer to play Tic-Tac-Toe."/><meta property="og:title" content="Teaching a computer to play Tic-Tac-Toe."/><meta property="og:description" content="Teaching a computer to play Tic-Tac-Toe."/><link rel="canonical" href="https://shariff-faleel.com/post/2018-07-17-tic-tac-toe"/><meta name="next-head-count" content="15"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css" integrity="sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB" crossorigin="anonymous"/><script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js" integrity="sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p" crossorigin="anonymous"></script><script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/css/f99a4114f4ea0774.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f99a4114f4ea0774.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-2c3d125ac9294a66.js" defer=""></script><script src="/_next/static/chunks/framework-fc97f3f1282ce3ed.js" defer=""></script><script src="/_next/static/chunks/main-1452d81522d66bc9.js" defer=""></script><script src="/_next/static/chunks/pages/_app-a6a74fa9337d991b.js" defer=""></script><script src="/_next/static/chunks/175675d1-a2f4b19cd9daa73f.js" defer=""></script><script src="/_next/static/chunks/706-5d4770c80855792c.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-8d11634093e6aeae.js" defer=""></script><script src="/_next/static/shM9jJEOXUFC_VB-Dk-j8/_buildManifest.js" defer=""></script><script src="/_next/static/shM9jJEOXUFC_VB-Dk-j8/_ssgManifest.js" defer=""></script><script src="/_next/static/shM9jJEOXUFC_VB-Dk-j8/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="flex flex-col min-h-screen bg-slate-700"><header class="bg-gray-800 mb-0 md:mb-8 py-1 text-gray-300 md:sticky top-0 left-0 right-0 drop-shadow-lg shadow-gray-900 z-10"><div class="container mx-auto flex flex-col md:flex-row gap-x-12 items-center justify-center"><a class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-4 py-2 items-center font-semibold text-lg" href="/">Shariff Faleel</a><a class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-4 py-2 items-center undefined" href="/posts">Posts</a><a class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-4 py-2 items-center undefined" href="/posts?pub=true">Publications</a><a class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-4 py-2 items-center group" href="/"><div>Quick links<!-- --><svg fill="currentColor" viewBox="0 0 20 20" class="inline w-4 h-4 mt-1 ml-1 transition-transform duration-200 transform md:-mt-1 rotate-0 group-hover:rotate-180"><path fill-rule="evenodd" d="M5.293 7.293a1 1 0 011.414 0L10 10.586l3.293-3.293a1 1 0 111.414 1.414l-4 4a1 1 0 01-1.414 0l-4-4a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></div><div class="absolute w-full mt-2 origin-top-right rounded-md shadow-lg w-fit transition-transform transition-opacity ease-in-out duration-200 opacity-0 scale-0 group-hover:opacity-100 group-hover:scale-100"><div class="p-2 bg-gray-700 rounded-md shadow dark-mode:bg-gray-700"><div class="block px-4 py-2 rounded-lg hover:bg-gray-600 hover:underline hover:decoration-2 items-center justify-left flex flex-row space-x-2" href="https://gist.github.com/ahmed-shariff"> <!-- --><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><title></title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></div><div>github-gists</div></div><div class="block px-4 py-2 rounded-lg hover:bg-gray-600 hover:underline hover:decoration-2 items-center justify-left flex flex-row space-x-2" href="/posts.xml"> <!-- --><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><title></title><path d="M19.199 24C19.199 13.467 10.533 4.8 0 4.8V0c13.165 0 24 10.835 24 24h-4.801zM3.291 17.415c1.814 0 3.293 1.479 3.293 3.295 0 1.813-1.485 3.29-3.301 3.29C1.47 24 0 22.526 0 20.71s1.475-3.294 3.291-3.295zM15.909 24h-4.665c0-6.169-5.075-11.245-11.244-11.245V8.09c8.727 0 15.909 7.184 15.909 15.91z"></path></svg></div><div>RSS feed</div></div></div></div></a></div></header><main class="container mx-auto flex-1"><div class="p-5 md:p-0 prose dark:prose-invert text-justify mx-auto max-w-screen-xl prose-img:block prose-img:m-auto prose-img:max-h-96 prose-p:w-full"><div class="text-xs text-slate-400">July 17, 2018<!-- --><div class="undefined flex gap-x-1 flex-wrap"><a class="text-gray-400" href="/posts?tags=random+thoughts">#random thoughts</a></div></div><h1 class="text-left">Teaching a computer to play Tic-Tac-Toe.<!-- --></h1><div><p>I am writing this article accompanying the <a href="https://github.com/H-A-I-L/tic-tac-toe">demonstration</a> prepared as part of a seminar for the first year undergraduates at the Department of Statistics and Computer Science, Faculty of Science, University of Peradeniya.</p>
<div class="message">
	I will post an updated version of this article on the Hanthana AI Lab's website when it goes live.
</div>
<h2>The web app</h2>
<p>Before we dive into the 'teaching a computer' part, let's have a look at the interface, the web app, through which will be used to play the game. The back-end of the web app is implemented using python and the front end is simply the same old html and javascript. You should be able to launch the server by running the following command:</p>
<pre><code class="hljs language-bash">python3 simple_server.py
</code></pre>
<p>This will display the address of the server which is usually: <code>http://localhost:8080</code>. Visiting this address should land you on a simple interface for two players to play tic-tac-toe. If you open the <code>index.html</code> file in the repository, you can see a simple implementation of how a game is judged.</p>
<h2>The model: How the computer plays</h2>
<p>Now to the meat of the article, how do we teach a computer to play this game. Among the many other approaches to playing games such as this, the approach that will be taking here is a machine learning approach. We are essentially trying to build a model that says what is the best possible next move which will ultimately lead to a win. We'll be using a simple neural network as the model here. Think of the model as a black box, it takes in the current state of the board and outputs the best next move. The implementation of this model is available in the python script at <code>models/deep_learning_feed_forward.py</code> in the repository. The model works as follows:</p>
<ul>
<li><strong>The input</strong>:
As the board of the game has 9 positions, the input is an array <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> of 9 elements, each representing one of the 9 boxes in the board. Each box can have one of the three values:
<ul>
<li><strong>0</strong>: if the box is empty.</li>
<li><strong>1</strong>: if the box is marked by the opposing player. (in this case the human player)</li>
<li><strong>2</strong>: if the box is marked by the current player. (in this case the computer)</li>
</ul>
</li>
<li><strong>The output</strong>:
The output is also an array of 9 elements. Just like the input, each element represents a box on the board. The values are probabilities. Simply put, the box with the highest probability is the box that will be chosen next by the computer.</li>
</ul>
<p>Note that the model we are using here does not have any form of memory. That is, it has not capacity to plan or remember it's previous moves. Hence, it purely predicts the next probable move based only on the current state of the board. <sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<h2>Training: Teaching the computer to play</h2>
<p>This model we define still doesn't know how to play on it's own. We have to teach it how to play. In machine learning we can call this process of teaching: training. That is, we have to train the model to predict the best next move based on the current state of the board. We do this by letting the model to make a prediction based on a input, we provide the model feedback on how correct/wrong the model's output is. Based on this feedback the model will adjust it's internal settings (parameters) to give a better output next time. We repeat this process until we are satisfied that the output of the model is consistently good.</p>
<p>We break the model's training in to two phases.</p>
<ul>
<li>How to predict valid positions: First we train the model to predict positions in the board that has not been marked by any of the players. For this, during each iteration of the training process, we generate a random board with positions partially filled and let the model predict a position. If the position is not empty, the feed back will be negative, where else if the position is not occupied, the feedback is positive.</li>
<li>How to predict positions that can lead to a win: Now that the model can predict valid positions, we'll train it to predict positions that can lead to a win. We do this by making a copy of the model and pitting it against itself. The opponent in this case is a previous version of the model. If the opponent loses the match the feedback will be positive, if the opponent wins the feedback will be negative, where else if the match concludes in a draw, the feedback will be zero.</li>
</ul>
<h2>Playing against the computer</h2>
<p>To play with the opponent, you'll have to have <a href="http://www.pytorch.org">pytorch</a> installed. Launch the server in the same way as described above and go to <code>http://localhost:8080/smart_player.html</code>. It is a similar interface as you'd have seen before, now the player 2 is the computer. As you make your move, the computer will make it's next move.</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Not necessaryily an array, it's a tensor, but for simplicity's sake I am calling it an array here. The definition of a tensor, broadly speaking, is a generalization of a matrix. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Though the model can be expanded to include memory and planning, it is out of the scope of this article. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
</div><div class="m-4 border-t-4 border-slate-400/25"></div><giscus-widget id="comments" repo="ahmed-shariff/ahmed-shariff.github.io" repoid="MDEwOlJlcG9zaXRvcnkxMjU3MDU3Nzc=" category="Announcements" categoryid="DIC_kwDOB34eMc4COpxh" mapping="pathname" reactionsenabled="1" emitmetadata="0" inputposition="top" theme="light" lang="en" loading="lazy"></giscus-widget></div></main><div class="fixed bottom-4 right-4 drop-shadow-lg z-50 shadow-gray-900"><button><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="fill-sky-400 fill-gray-900 rounded-full bg-slate-600 hover:bg-slate-500" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M256 464c114.9 0 208-93.1 208-208S370.9 48 256 48 48 141.1 48 256s93.1 208 208 208zm0-244.5l-81.1 81.9c-7.5 7.5-19.8 7.5-27.3 0s-7.5-19.8 0-27.3l95.7-95.4c7.3-7.3 19.1-7.5 26.6-.6l94.3 94c3.8 3.8 5.7 8.7 5.7 13.7 0 4.9-1.9 9.9-5.6 13.6-7.5 7.5-19.7 7.6-27.3 0l-81-79.9z"></path></svg></button></div><footer class="bg-gray-800 mt-8 py-4 text-gray-300 drop-shadow-lg shadow-gray-900"><div class="container mx-auto flex justify-center text-sm">© 2023 Shariff Faleel</div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"slug":"2018-07-17-tic-tac-toe","frontmatter":{"layout":"post","comments":true,"title":"Teaching a computer to play Tic-Tac-Toe.","tags":["Random thoughts"],"tagline":"A simple demonstration of teaching a computer to play tic-tac-toe. This is part of a demonstration made for the first year undergraduates."},"content":"I am writing this article accompanying the [demonstration](https://github.com/H-A-I-L/tic-tac-toe) prepared as part of a seminar for the first year undergraduates at the Department of Statistics and Computer Science, Faculty of Science, University of Peradeniya.\n\n\u003cdiv class=\"message\"\u003e\n\tI will post an updated version of this article on the Hanthana AI Lab's website when it goes live.\n\u003c/div\u003e\n\n## The web app\n\nBefore we dive into the 'teaching a computer' part, let's have a look at the interface, the web app, through which will be used to play the game. The back-end of the web app is implemented using python and the front end is simply the same old html and javascript. You should be able to launch the server by running the following command:\n```bash\npython3 simple_server.py\n```\n\nThis will display the address of the server which is usually: \u003ccode\u003ehttp://localhost:8080\u003c/code\u003e. Visiting this address should land you on a simple interface for two players to play tic-tac-toe. If you open the \u003ccode\u003eindex.html\u003c/code\u003e file in the repository, you can see a simple implementation of how a game is judged.\n\n## The model: How the computer plays\n\nNow to the meat of the article, how do we teach a computer to play this game. Among the many other approaches to playing games such as this, the approach that will be taking here is a machine learning approach. We are essentially trying to build a model that says what is the best possible next move which will ultimately lead to a win. We'll be using a simple neural network as the model here. Think of the model as a black box, it takes in the current state of the board and outputs the best next move. The implementation of this model is available in the python script at \u003ccode\u003emodels/deep_learning_feed_forward.py\u003c/code\u003e in the repository. The model works as follows:\n- **The input**:\n  As the board of the game has 9 positions, the input is an array [^fn-arry_vs_tensor] of 9 elements, each representing one of the 9 boxes in the board. Each box can have one of the three values:\n  - **0**: if the box is empty.\n  - **1**: if the box is marked by the opposing player. (in this case the human player)\n  - **2**: if the box is marked by the current player. (in this case the computer)\n- **The output**:\n  The output is also an array of 9 elements. Just like the input, each element represents a box on the board. The values are probabilities. Simply put, the box with the highest probability is the box that will be chosen next by the computer.\n  \nNote that the model we are using here does not have any form of memory. That is, it has not capacity to plan or remember it's previous moves. Hence, it purely predicts the next probable move based only on the current state of the board. [^fn-only_ff]\n  \n## Training: Teaching the computer to play\n\nThis model we define still doesn't know how to play on it's own. We have to teach it how to play. In machine learning we can call this process of teaching: training. That is, we have to train the model to predict the best next move based on the current state of the board. We do this by letting the model to make a prediction based on a input, we provide the model feedback on how correct/wrong the model's output is. Based on this feedback the model will adjust it's internal settings (parameters) to give a better output next time. We repeat this process until we are satisfied that the output of the model is consistently good. \n\nWe break the model's training in to two phases.\n- How to predict valid positions: First we train the model to predict positions in the board that has not been marked by any of the players. For this, during each iteration of the training process, we generate a random board with positions partially filled and let the model predict a position. If the position is not empty, the feed back will be negative, where else if the position is not occupied, the feedback is positive.\n- How to predict positions that can lead to a win: Now that the model can predict valid positions, we'll train it to predict positions that can lead to a win. We do this by making a copy of the model and pitting it against itself. The opponent in this case is a previous version of the model. If the opponent loses the match the feedback will be positive, if the opponent wins the feedback will be negative, where else if the match concludes in a draw, the feedback will be zero.\n\n## Playing against the computer\n\nTo play with the opponent, you'll have to have [pytorch](http://www.pytorch.org) installed. Launch the server in the same way as described above and go to \u003ccode\u003ehttp://localhost:8080/smart_player.html\u003c/code\u003e. It is a similar interface as you'd have seen before, now the player 2 is the computer. As you make your move, the computer will make it's next move. \n\n[^fn-arry_vs_tensor]: Not necessaryily an array, it's a tensor, but for simplicity's sake I am calling it an array here. The definition of a tensor, broadly speaking, is a generalization of a matrix.\n\n[^fn-only_ff]: Though the model can be expanded to include memory and planning, it is out of the scope of this article.\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2018-07-17-tic-tac-toe"},"buildId":"shM9jJEOXUFC_VB-Dk-j8","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>