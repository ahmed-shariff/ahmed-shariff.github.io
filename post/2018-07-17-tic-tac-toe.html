<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/e94d3d602c719429.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e94d3d602c719429.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-b84c169ac90f8974.js" defer=""></script><script src="/_next/static/chunks/framework-00b57966872fc495.js" defer=""></script><script src="/_next/static/chunks/main-1452d81522d66bc9.js" defer=""></script><script src="/_next/static/chunks/pages/_app-b0e469cf26f5278f.js" defer=""></script><script src="/_next/static/chunks/175675d1-a2f4b19cd9daa73f.js" defer=""></script><script src="/_next/static/chunks/980-0fae37084f488ec8.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-c00e23fa748dc7e0.js" defer=""></script><script src="/_next/static/DbfrYlt7puuYzlvH1AiOG/_buildManifest.js" defer=""></script><script src="/_next/static/DbfrYlt7puuYzlvH1AiOG/_ssgManifest.js" defer=""></script><script src="/_next/static/DbfrYlt7puuYzlvH1AiOG/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="flex flex-col min-h-screen"><header class="bg-sky-100 mb-8 py-4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css" integrity="sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB" crossorigin="anonymous"/><script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js" integrity="sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p" crossorigin="anonymous"></script><script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script><div class="container mx-auto flex justify-center"><a href="/">Shariff Faleel</a></div></header><main class="container mx-auto flex-1"><div class="prose text-justify mx-auto max-w-screen-xl prose-img:block prose-img:m-auto prose-img:max-h-96 prose-p:w-full"><h1>Teaching a computer to play Tic-Tac-Toe.</h1><div><p>I am writing this article accompanying the <a href="https://github.com/H-A-I-L/tic-tac-toe">demonstration</a> prepared as part of a seminar for the first year undergraduates at the Department of Statistics and Computer Science, Faculty of Science, University of Peradeniya.</p>
<div class="message">
	I will post an updated version of this article on the Hanthana AI Lab's website when it goes live.
</div>
<h2>The web app</h2>
<p>Before we dive into the 'teaching a computer' part, let's have a look at the interface, the web app, through which will be used to play the game. The back-end of the web app is implemented using python and the front end is simply the same old html and javascript. You should be able to launch the server by running the following command:</p>
<pre><code class="language-bash">python3 simple_server.py
</code></pre>
<p>This will display the address of the server which is usually: <code>http://localhost:8080</code>. Visiting this address should land you on a simple interface for two players to play tic-tac-toe. If you open the <code>index.html</code> file in the repository, you can see a simple implementation of how a game is judged.</p>
<h2>The model: How the computer plays</h2>
<p>Now to the meat of the article, how do we teach a computer to play this game. Among the many other approaches to playing games such as this, the approach that will be taking here is a machine learning approach. We are essentially trying to build a model that says what is the best possible next move which will ultimately lead to a win. We'll be using a simple neural network as the model here. Think of the model as a black box, it takes in the current state of the board and outputs the best next move. The implementation of this model is available in the python script at <code>models/deep_learning_feed_forward.py</code> in the repository. The model works as follows:</p>
<ul>
<li><strong>The input</strong>:
As the board of the game has 9 positions, the input is an array <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> of 9 elements, each representing one of the 9 boxes in the board. Each box can have one of the three values:
<ul>
<li><strong>0</strong>: if the box is empty.</li>
<li><strong>1</strong>: if the box is marked by the opposing player. (in this case the human player)</li>
<li><strong>2</strong>: if the box is marked by the current player. (in this case the computer)</li>
</ul>
</li>
<li><strong>The output</strong>:
The output is also an array of 9 elements. Just like the input, each element represents a box on the board. The values are probabilities. Simply put, the box with the highest probability is the box that will be chosen next by the computer.</li>
</ul>
<p>Note that the model we are using here does not have any form of memory. That is, it has not capacity to plan or remember it's previous moves. Hence, it purely predicts the next probable move based only on the current state of the board. <sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<h2>Training: Teaching the computer to play</h2>
<p>This model we define still doesn't know how to play on it's own. We have to teach it how to play. In machine learning we can call this process of teaching: training. That is, we have to train the model to predict the best next move based on the current state of the board. We do this by letting the model to make a prediction based on a input, we provide the model feedback on how correct/wrong the model's output is. Based on this feedback the model will adjust it's internal settings (parameters) to give a better output next time. We repeat this process until we are satisfied that the output of the model is consistently good.</p>
<p>We break the model's training in to two phases.</p>
<ul>
<li>How to predict valid positions: First we train the model to predict positions in the board that has not been marked by any of the players. For this, during each iteration of the training process, we generate a random board with positions partially filled and let the model predict a position. If the position is not empty, the feed back will be negative, where else if the position is not occupied, the feedback is positive.</li>
<li>How to predict positions that can lead to a win: Now that the model can predict valid positions, we'll train it to predict positions that can lead to a win. We do this by making a copy of the model and pitting it against itself. The opponent in this case is a previous version of the model. If the opponent loses the match the feedback will be positive, if the opponent wins the feedback will be negative, where else if the match concludes in a draw, the feedback will be zero.</li>
</ul>
<h2>Playing against the computer</h2>
<p>To play with the opponent, you'll have to have <a href="http://www.pytorch.org">pytorch</a> installed. Launch the server in the same way as described above and go to <code>http://localhost:8080/smart_player.html</code>. It is a similar interface as you'd have seen before, now the player 2 is the computer. As you make your move, the computer will make it's next move.</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Not necessaryily an array, it's a tensor, but for simplicity's sake I am calling it an array here. The definition of a tensor, broadly speaking, is a generalization of a matrix. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Though the model can be expanded to include memory and planning, it is out of the scope of this article. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
</div><giscus-widget id="comments" repo="ahmed-shariff/ahmed-shariff.github.io" repoid="MDEwOlJlcG9zaXRvcnkxMjU3MDU3Nzc=" category="Announcements" categoryid="DIC_kwDOB34eMc4COpxh" mapping="pathname" reactionsenabled="1" emitmetadata="0" inputposition="top" theme="light" lang="en" loading="lazy"></giscus-widget></div></main><footer class="bg-sky-100 mt-8 py-4"><div class="container mx-auto flex justify-center text-sm">© 2022 Shariff Faleel</div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"layout":"post","comments":true,"title":"Teaching a computer to play Tic-Tac-Toe.","tags":["Random thoughts"],"tagline":"A simple demonstration of teaching a computer to play tic-tac-toe. This is part of a demonstration made for the first year undergraduates."},"content":"I am writing this article accompanying the [demonstration](https://github.com/H-A-I-L/tic-tac-toe) prepared as part of a seminar for the first year undergraduates at the Department of Statistics and Computer Science, Faculty of Science, University of Peradeniya.\r\n\r\n\u003cdiv class=\"message\"\u003e\r\n\tI will post an updated version of this article on the Hanthana AI Lab's website when it goes live.\r\n\u003c/div\u003e\r\n\r\n## The web app\r\n\r\nBefore we dive into the 'teaching a computer' part, let's have a look at the interface, the web app, through which will be used to play the game. The back-end of the web app is implemented using python and the front end is simply the same old html and javascript. You should be able to launch the server by running the following command:\r\n```bash\r\npython3 simple_server.py\r\n```\r\n\r\nThis will display the address of the server which is usually: \u003ccode\u003ehttp://localhost:8080\u003c/code\u003e. Visiting this address should land you on a simple interface for two players to play tic-tac-toe. If you open the \u003ccode\u003eindex.html\u003c/code\u003e file in the repository, you can see a simple implementation of how a game is judged.\r\n\r\n## The model: How the computer plays\r\n\r\nNow to the meat of the article, how do we teach a computer to play this game. Among the many other approaches to playing games such as this, the approach that will be taking here is a machine learning approach. We are essentially trying to build a model that says what is the best possible next move which will ultimately lead to a win. We'll be using a simple neural network as the model here. Think of the model as a black box, it takes in the current state of the board and outputs the best next move. The implementation of this model is available in the python script at \u003ccode\u003emodels/deep_learning_feed_forward.py\u003c/code\u003e in the repository. The model works as follows:\r\n- **The input**:\r\n  As the board of the game has 9 positions, the input is an array [^fn-arry_vs_tensor] of 9 elements, each representing one of the 9 boxes in the board. Each box can have one of the three values:\r\n  - **0**: if the box is empty.\r\n  - **1**: if the box is marked by the opposing player. (in this case the human player)\r\n  - **2**: if the box is marked by the current player. (in this case the computer)\r\n- **The output**:\r\n  The output is also an array of 9 elements. Just like the input, each element represents a box on the board. The values are probabilities. Simply put, the box with the highest probability is the box that will be chosen next by the computer.\r\n  \r\nNote that the model we are using here does not have any form of memory. That is, it has not capacity to plan or remember it's previous moves. Hence, it purely predicts the next probable move based only on the current state of the board. [^fn-only_ff]\r\n  \r\n## Training: Teaching the computer to play\r\n\r\nThis model we define still doesn't know how to play on it's own. We have to teach it how to play. In machine learning we can call this process of teaching: training. That is, we have to train the model to predict the best next move based on the current state of the board. We do this by letting the model to make a prediction based on a input, we provide the model feedback on how correct/wrong the model's output is. Based on this feedback the model will adjust it's internal settings (parameters) to give a better output next time. We repeat this process until we are satisfied that the output of the model is consistently good. \r\n\r\nWe break the model's training in to two phases.\r\n- How to predict valid positions: First we train the model to predict positions in the board that has not been marked by any of the players. For this, during each iteration of the training process, we generate a random board with positions partially filled and let the model predict a position. If the position is not empty, the feed back will be negative, where else if the position is not occupied, the feedback is positive.\r\n- How to predict positions that can lead to a win: Now that the model can predict valid positions, we'll train it to predict positions that can lead to a win. We do this by making a copy of the model and pitting it against itself. The opponent in this case is a previous version of the model. If the opponent loses the match the feedback will be positive, if the opponent wins the feedback will be negative, where else if the match concludes in a draw, the feedback will be zero.\r\n\r\n## Playing against the computer\r\n\r\nTo play with the opponent, you'll have to have [pytorch](http://www.pytorch.org) installed. Launch the server in the same way as described above and go to \u003ccode\u003ehttp://localhost:8080/smart_player.html\u003c/code\u003e. It is a similar interface as you'd have seen before, now the player 2 is the computer. As you make your move, the computer will make it's next move. \r\n\r\n[^fn-arry_vs_tensor]: Not necessaryily an array, it's a tensor, but for simplicity's sake I am calling it an array here. The definition of a tensor, broadly speaking, is a generalization of a matrix.\r\n\r\n[^fn-only_ff]: Though the model can be expanded to include memory and planning, it is out of the scope of this article.\r\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2018-07-17-tic-tac-toe"},"buildId":"DbfrYlt7puuYzlvH1AiOG","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>