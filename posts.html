<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/6853c5fc042b5992.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6853c5fc042b5992.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-4de48dbd32378f56.js" defer=""></script><script src="/_next/static/chunks/framework-00b57966872fc495.js" defer=""></script><script src="/_next/static/chunks/main-1452d81522d66bc9.js" defer=""></script><script src="/_next/static/chunks/pages/_app-19620cb7a5c3b4e8.js" defer=""></script><script src="/_next/static/chunks/175675d1-a2f4b19cd9daa73f.js" defer=""></script><script src="/_next/static/chunks/1a48c3c1-f64bf69573c9d42a.js" defer=""></script><script src="/_next/static/chunks/706-5d4770c80855792c.js" defer=""></script><script src="/_next/static/chunks/926-fa17308df63993d2.js" defer=""></script><script src="/_next/static/chunks/pages/posts-334e647ad9d5b0da.js" defer=""></script><script src="/_next/static/6uFZU0TQNLkSN4GAj_HCN/_buildManifest.js" defer=""></script><script src="/_next/static/6uFZU0TQNLkSN4GAj_HCN/_ssgManifest.js" defer=""></script><script src="/_next/static/6uFZU0TQNLkSN4GAj_HCN/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="flex flex-col min-h-screen bg-slate-700"><header class="bg-gray-800 mb-0 md:mb-8 py-1 text-gray-300 md:sticky top-0 left-0 right-0 drop-shadow-lg shadow-gray-900 z-10"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css" integrity="sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB" crossorigin="anonymous"/><script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js" integrity="sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p" crossorigin="anonymous"></script><script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script><div class="container mx-auto flex flex-col md:flex-row gap-x-12 items-center justify-center"><a class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-4 py-2 items-center font-semibold text-lg" href="/">Shariff Faleel</a><a class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-4 py-2 items-center undefined" href="/posts">Posts</a><a class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-4 py-2 items-center undefined" href="/posts?pub=true">Publications</a><a class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-4 py-2 items-center group" href="/"><div>Quick links<!-- --><svg fill="currentColor" viewBox="0 0 20 20" class="inline w-4 h-4 mt-1 ml-1 transition-transform duration-200 transform md:-mt-1 rotate-0 group-hover:rotate-180"><path fill-rule="evenodd" d="M5.293 7.293a1 1 0 011.414 0L10 10.586l3.293-3.293a1 1 0 111.414 1.414l-4 4a1 1 0 01-1.414 0l-4-4a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></div><div class="absolute w-full mt-2 origin-top-right rounded-md shadow-lg w-fit transition-transform transition-opacity ease-in-out duration-200 opacity-0 scale-0 group-hover:opacity-100 group-hover:scale-100"><div class="p-2 bg-gray-700 rounded-md shadow dark-mode:bg-gray-700"><div class="block px-4 py-2 rounded-lg hover:bg-gray-600 hover:underline hover:decoration-2 items-center justify-left flex flex-row space-x-2" href="https://gist.github.com/ahmed-shariff"> <!-- --><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><title></title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></div><div>github-gists</div></div><div class="block px-4 py-2 rounded-lg hover:bg-gray-600 hover:underline hover:decoration-2 items-center justify-left flex flex-row space-x-2" href="/posts.xml"> <!-- --><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><title></title><path d="M19.199 24C19.199 13.467 10.533 4.8 0 4.8V0c13.165 0 24 10.835 24 24h-4.801zM3.291 17.415c1.814 0 3.293 1.479 3.293 3.295 0 1.813-1.485 3.29-3.301 3.29C1.47 24 0 22.526 0 20.71s1.475-3.294 3.291-3.295zM15.909 24h-4.665c0-6.169-5.075-11.245-11.244-11.245V8.09c8.727 0 15.909 7.184 15.909 15.91z"></path></svg></div><div>RSS feed</div></div></div></div></a></div></header><main class="container mx-auto flex-1"><div><div class="grid grid-cols-1 p-0 md:px-20 mt-10"><h1 class="text-xl text-center text-slate-100">Posts and Publications</h1><hr class="m-2"/><div class="m-2 flex w-100 item-center content-center flex-row"><button class="transition duration-100 shadow-none p-1 hover:shadow hover:bg-slate-600 rounded">Tags<!-- --><svg fill="currentColor" viewBox="0 0 20 20" class="inline w-4 h-4 m-1 transition-transform duration-200 transform md:-mt-1 rotate-0"><path fill-rule="evenodd" d="M5.293 7.293a1 1 0 011.414 0L10 10.586l3.293-3.293a1 1 0 111.414 1.414l-4 4a1 1 0 01-1.414 0l-4-4a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button><button class="ml-4 transition duration-100 shadow-none p-1 hover:shadow hover:bg-slate-600 rounded">Publications Only</button><a href="/posts.xml" class="flex items-center flex-grow justify-end px-3"><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" class="fill-sky-400 fill-slate-500" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><title></title><path d="M19.199 24C19.199 13.467 10.533 4.8 0 4.8V0c13.165 0 24 10.835 24 24h-4.801zM3.291 17.415c1.814 0 3.293 1.479 3.293 3.295 0 1.813-1.485 3.29-3.301 3.29C1.47 24 0 22.526 0 20.71s1.475-3.294 3.291-3.295zM15.909 24h-4.665c0-6.169-5.075-11.245-11.244-11.245V8.09c8.727 0 15.909 7.184 15.909 15.91z"></path></svg></a></div><div class="mx-2 transition-all duration-200 h-0 scale-y-0 -translate-y-1/2 opacity-0 flex gap-x-1 flex-wrap"><a class="text-gray-400" href="/posts?tags=oculus">#oculus</a><a class="text-gray-400" href="/posts?tags=vr">#vr</a><a class="text-gray-400" href="/posts?tags=guide">#guide</a><a class="text-gray-400" href="/posts?tags=javascript">#javascript</a><a class="text-gray-400" href="/posts?tags=react">#react</a><a class="text-gray-400" href="/posts?tags=next">#next</a><a class="text-gray-400" href="/posts?tags=course">#course</a><a class="text-gray-400" href="/posts?tags=hci">#hci</a><a class="text-gray-400" href="/posts?tags=emacs">#emacs</a><a class="text-gray-400" href="/posts?tags=org">#org</a><a class="text-gray-400" href="/posts?tags=machine+learning">#machine learning</a><a class="text-gray-400" href="/posts?tags=deep+learning">#deep learning</a><a class="text-gray-400" href="/posts?tags=nlp">#nlp</a><a class="text-gray-400" href="/posts?tags=random+thoughts">#random thoughts</a><a class="text-gray-400" href="/posts?tags=reference-management">#reference-management</a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2022-09-16-profiling_loading_org_files"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Profiling file loading times for org mode<!-- --></h1><div class="text-xs -mt-2 text-slate-400">September 16, 2022<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#emacs</div><div class="text-gray-400">#org</div></div></div><div class="text-xs ">The loading times of files was starting to become an issue as I started switching to the &#x27;one file per note` approach in my org-roam database. Documenting some profiling I did to see what I can do about it.</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2022-07-29-pub-ali22_edgeselect"><div class="p-3 grow min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>EdgeSelect: Smartwatch Data Interaction with Minimal Screen Occlusion</h1><div class="text-xs -mt-2"><p>Ali Neshati; Aaron Salo; <b>Shariff AM Faleel</b>; Ziming Li; Hai-Ning Liang; Celine Latulipe; Pourang Irani</p>
</div><div class="text-xs -mt-2 text-slate-400 flex flex-wrap gap-x-4"><div>November 7, 2022<!-- --></div><div>ICMI &#x27;22 (Accepted)</div><div>TBA</div></div></div><div class="flex h-full bg-slate-500 p-3 content-center items-center "><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="fill-sky-400 fill-slate-100" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M113.5 281.2v85.3L256 448l142.5-81.5v-85.3L256 362.7l-142.5-81.5zM256 64L32 192l224 128 183.3-104.7v147.4H480V192L256 64z"></path></svg></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2022-06-13-pub-alallah22_ssca"><div class="p-3 grow min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>SSCA: Situated Space-time Cube Analytics</h1><div class="text-xs -mt-2"><p>Fouad Alallah, <b>Shariff AM Faleel</b>, Yumiko Sakamoto, Bradley Rey, Pourang Irani</p>
</div><div class="text-xs -mt-2 text-slate-400 flex flex-wrap gap-x-4"><div>June 13, 2022<!-- --></div><div>EuroVis &#x27;22</div><div>10.2312/evs20221088</div></div></div><div class="flex h-full bg-slate-500 p-3 content-center items-center "><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="fill-sky-400 fill-slate-100" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M113.5 281.2v85.3L256 448l142.5-81.5v-85.3L256 362.7l-142.5-81.5zM256 64L32 192l224 128 183.3-104.7v147.4H480V192L256 64z"></path></svg></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2022-05-21-lit-mangaement"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Reference Management: What am I managing?<!-- --></h1><div class="text-xs -mt-2 text-slate-400">May 21, 2022<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#org</div><div class="text-gray-400">#emacs</div><div class="text-gray-400">#reference-management</div></div></div><div class="text-xs ">Documenting the features of my reference management system along with a wish list.</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2022-05-02-oculus_setup"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Setting up Oculus Quest 2 for development with Unity<!-- --></h1><div class="text-xs -mt-2 text-slate-400">May 2, 2022<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#oculus</div><div class="text-gray-400">#vr</div><div class="text-gray-400">#guide</div></div></div><div class="text-xs ">Step-by-step guide to setting up oculus for development with unity.</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2022-04-19-nextjs-gh-pages"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Personal website with nextjs and github pages<!-- --></h1><div class="text-xs -mt-2 text-slate-400">April 19, 2022<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#javascript</div><div class="text-gray-400">#react</div><div class="text-gray-400">#next</div><div class="text-gray-400">#guide</div></div></div><div class="text-xs ">Summery of how I went about setting up my personal website which with markdown blog on github pages using nextjs.</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2021-08-27-pub-shariff21_hpui"><div class="p-3 grow min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>HPUI: Hand Proximate User Interfaces for One-Handed Interactions on Head Mounted Displays</h1><div class="text-xs -mt-2"><p><b>Shariff AM Faleel</b>; Michael Gammon; Kevin Fan; Da-Yuan Huang; Wei Li; Pourang Irani</p>
</div><div class="text-xs -mt-2 text-slate-400 flex flex-wrap gap-x-4"><div>August 27, 2021<!-- --></div><div>TVCG (ISMAR &#x27;21)</div><div>10.1109/TVCG.2021.3106493</div></div></div><div class="flex h-full bg-slate-500 p-3 content-center items-center "><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="fill-sky-400 fill-slate-100" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M113.5 281.2v85.3L256 448l142.5-81.5v-85.3L256 362.7l-142.5-81.5zM256 64L32 192l224 128 183.3-104.7v147.4H480V192L256 64z"></path></svg></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2021-07-06-pub-shariff21_writely"><div class="p-3 grow min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Writely: Force Feedback for Non-Dominant Hand Writing Training</h1><div class="text-xs -mt-2"><p><b>Shariff AM Faleel</b>; Bibhushan Raj Joshi; Bradley Rey</p>
</div><div class="text-xs -mt-2 text-slate-400 flex flex-wrap gap-x-4"><div>July 6, 2021<!-- --></div><div>WHC &#x27;21</div><div>WHC49131.2021.9517209</div></div></div><div class="flex h-full bg-slate-500 p-3 content-center items-center "><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="fill-sky-400 fill-slate-100" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M113.5 281.2v85.3L256 448l142.5-81.5v-85.3L256 362.7l-142.5-81.5zM256 64L32 192l224 128 183.3-104.7v147.4H480V192L256 64z"></path></svg></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2021-05-07-pub-ali21_bezelglide"><div class="p-3 grow min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>BezelGlide: Interacting with Graphs on Smartwatches with Minimal Screen Occlusion</h1><div class="text-xs -mt-2"><p>Ali Neshati; Bradley Rey; <b>Ahmed Shariff Mohommed Faleel</b>; Sandra Bardot; Celine Latulipe; Pourang Irani</p>
</div><div class="text-xs -mt-2 text-slate-400 flex flex-wrap gap-x-4"><div>May 7, 2021<!-- --></div><div>CHI &#x27;21</div><div>10.1145/3411764.3445201</div></div></div><div class="flex h-full bg-slate-500 p-3 content-center items-center "><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="fill-sky-400 fill-slate-100" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M113.5 281.2v85.3L256 448l142.5-81.5v-85.3L256 362.7l-142.5-81.5zM256 64L32 192l224 128 183.3-104.7v147.4H480V192L256 64z"></path></svg></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2021-03-29-canhap_writel_i2"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Writely (Part 2) - Face the kraken<!-- --></h1><div class="text-xs -mt-2 text-slate-400">March 29, 2021<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#course</div><div class="text-gray-400">#hci</div></div></div><div class="text-xs ">Second iteration of the canhap project, where wrestle the haptic implementations on our system.</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2021-03-12-canhap-lab3"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Talking with haptics<!-- --></h1><div class="text-xs -mt-2 text-slate-400">March 12, 2021<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#course</div><div class="text-gray-400">#hci</div></div></div><div class="text-xs ">Playing with PID controllers and haply</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2021-03-08-canhap_writely_i1"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Writely (Part 1) - Into the belly of the beast<!-- --></h1><div class="text-xs -mt-2 text-slate-400">March 8, 2021<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#course</div><div class="text-gray-400">#hci</div></div></div><div class="text-xs ">First iteration of using haply to develop a system for training writing.</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2021-02-26-canhap-lab4"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>PID with Haply<!-- --></h1><div class="text-xs -mt-2 text-slate-400">February 26, 2021<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#course</div><div class="text-gray-400">#hci</div></div></div><div class="text-xs ">Playing with PID controllers and haply</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2021-02-05-canhap-lab2"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Exploring Haply<!-- --></h1><div class="text-xs -mt-2 text-slate-400">February 5, 2021<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#course</div><div class="text-gray-400">#hci</div></div></div><div class="text-xs ">Introducing myself to using haply, processing and fisca</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2021-01-29-forky"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Make forky walk - Sketching lab<!-- --></h1><div class="text-xs -mt-2 text-slate-400">January 29, 2021<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#course</div><div class="text-gray-400">#hci</div></div></div><div class="text-xs ">It&#x27;s trash</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2021-01-27-org_ref_brain"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Using org mode for bibliography management<!-- --></h1><div class="text-xs -mt-2 text-slate-400">January 27, 2021<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#emacs</div><div class="text-gray-400">#org</div><div class="text-gray-400">#reference-management</div></div></div><div class="text-xs ">All hail emacs! All hail org-mode!</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2020-05-27-pub-yurii20_using_guess"><div class="p-3 grow min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Using guessability framework: age-related differences in hand gesture interaction</h1><div class="text-xs -mt-2"><p>Yurii Vasylkiv; Ali Neshati; <b>Shariff AM Faleel</b>; Yumiko Sakamoto; Pourang Irani</p>
</div><div class="text-xs -mt-2 text-slate-400 flex flex-wrap gap-x-4"><div>May 27, 2020<!-- --></div><div>Augmented Human (AH &#x27;20)</div><div>10.1145/3396339.3396394</div></div></div><div class="flex h-full bg-slate-500 p-3 content-center items-center "><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="fill-sky-400 fill-slate-100" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M113.5 281.2v85.3L256 448l142.5-81.5v-85.3L256 362.7l-142.5-81.5zM256 64L32 192l224 128 183.3-104.7v147.4H480V192L256 64z"></path></svg></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2020-05-27-pub-shariff20_user_gesture"><div class="p-3 grow min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>User Gesture Elicitation of Common Smartphone Tasks for Hand Proximate User Interfaces</h1><div class="text-xs -mt-2"><p><b>Shariff AM Faleel</b>; Michael Gammon; Yumiko Sakamoto; Carlo Menon; Pourang Irani</p>
</div><div class="text-xs -mt-2 text-slate-400 flex flex-wrap gap-x-4"><div>May 27, 2020<!-- --></div><div>Augmented Human (AH &#x27;20)</div><div>10.1145/3396339.3396363</div></div></div><div class="flex h-full bg-slate-500 p-3 content-center items-center "><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="fill-sky-400 fill-slate-100" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M113.5 281.2v85.3L256 448l142.5-81.5v-85.3L256 362.7l-142.5-81.5zM256 64L32 192l224 128 183.3-104.7v147.4H480V192L256 64z"></path></svg></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2019-07-05-pub-shariff19_dialog_manager"><div class="p-3 grow min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>A Novel Dialogue Manager Model for Spoken Dialogue Systems Based on User Input Learning</h1><div class="text-xs -mt-2"><p><b>M.F. Ahmed Shariff</b>; Ruwan D. Nawarathna</p>
</div><div class="text-xs -mt-2 text-slate-400 flex flex-wrap gap-x-4"><div>July 5, 2019<!-- --></div><div>SLAAI-ICAI &#x27;18</div><div>10.1007/978-981-13-9129-3_14</div></div></div><div class="flex h-full bg-slate-500 p-3 content-center items-center "><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="fill-sky-400 fill-slate-100" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M113.5 281.2v85.3L256 448l142.5-81.5v-85.3L256 362.7l-142.5-81.5zM256 64L32 192l224 128 183.3-104.7v147.4H480V192L256 64z"></path></svg></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2019-02-18-labeling_process"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>The game of labeling<!-- --></h1><div class="text-xs -mt-2 text-slate-400">February 18, 2019<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#machine learning</div></div></div><div class="text-xs ">A summery of the labeing process I follow</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2019-01-08-nlp_retrospective"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Building a dialogue manager - A retrospective<!-- --></h1><div class="text-xs -mt-2 text-slate-400">January 8, 2019<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#deep learning</div><div class="text-gray-400">#nlp</div></div></div><div class="text-xs ">Lesons learnt and thoughts after working on the dialogue management model</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2018-11-01-article_review_using_git"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Article review using git<!-- --></h1><div class="text-xs -mt-2 text-slate-400">November 1, 2018<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#random thoughts</div></div></div><div class="text-xs ">Implementing a review system for articles using git</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2018-09-10-quantum_computing"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Quantum computing<!-- --></h1><div class="text-xs -mt-2 text-slate-400">September 10, 2018<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#random thoughts</div></div></div><div class="text-xs ">A brief introduction to the basics of quantum computing.</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2018-08-31-how-the-mind-works"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Steven Pinker&#x27;s &#x27;How the mind works&#x27;<!-- --></h1><div class="text-xs -mt-2 text-slate-400">August 31, 2018<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#random thoughts</div></div></div><div class="text-xs ">A few ideas in the book I found interesting. (Though I don&#x27;t fully understand or accept/agree with them all)</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2018-08-01-mlp_file_structure"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Practices I follow with the machine learning pipeline<!-- --></h1><div class="text-xs -mt-2 text-slate-400">August 1, 2018<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#deep learning</div></div></div><div class="text-xs ">While the ml-pipeline solves some of the problems I encounter, it doesn&#x27;t solve all of them. Here I describe my process beyond the pipeline.</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2018-07-26-ml-problems"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>ML problems I run into<!-- --></h1><div class="text-xs -mt-2 text-slate-400">July 26, 2018<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#random thoughts</div></div></div><div class="text-xs ">An ongoing list of problems I run into when using deep learning</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2018-07-17-tic-tac-toe"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Teaching a computer to play Tic-Tac-Toe.<!-- --></h1><div class="text-xs -mt-2 text-slate-400">July 17, 2018<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#random thoughts</div></div></div><div class="text-xs ">A simple demonstration of teaching a computer to play tic-tac-toe. This is part of a demonstration made for the first year undergraduates.</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2018-06-13-qubits-opened"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Opening of the qubits lab<!-- --></h1><div class="text-xs -mt-2 text-slate-400">June 13, 2018<!-- --></div><div class="text-xs "></div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2018-06-11-Experiment-log"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Experiment log - How I keep track of my ML experiments<!-- --></h1><div class="text-xs -mt-2 text-slate-400">June 11, 2018<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#machine learning</div></div></div><div class="text-xs ">In order to reduce the clutter, I keep track of the experiments using a emacs org-mode.</div></div></a></div><div class="border border-gray-200 m-2 rounded-xl shadow-md shadow-gray-800 overflow-hidden flex flex-col text-ellipsis h-500 transition transform duration-500 opacity-0 translate-y-16"><a class="flex w-100 text-left button" href="/post/2018-04-25-why-no-posting"><div class="p-3 min-h-full prose dark:prose-invert prose-sm max-w-none prose-h1:text-base prose-h1:font-normal"><h1>Why you no posting stuff?<!-- --></h1><div class="text-xs -mt-2 text-slate-400">April 25, 2018<!-- --><div class="undefined flex gap-x-1 flex-wrap"><div class="text-gray-400">#random thoughts</div></div></div><div class="text-xs ">Why indeed......</div></div></a></div><div class="flex place-content-center m-2 text-stone-200 bg-gray-800"><ul class="items-stretch justify-center inline-flex items"><li class="previous disabled"><a class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-2 py-1 mt-1 mx-1 items-center inline-block text-base " tabindex="-1" role="button" aria-disabled="true" aria-label="Previous page" rel="prev"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="fill-sky-400 fill-stone-200" height="30" width="30" xmlns="http://www.w3.org/2000/svg"><path d="M13.293 6.293 7.586 12l5.707 5.707 1.414-1.414L10.414 12l4.293-4.293z"></path></svg></a></li><li class="selected"><a rel="canonical" role="button" class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-2 py-1 mt-1 mx-1 items-center inline-block text-base bg-gray-600" tabindex="-1" aria-label="Page 1 is your current page" aria-current="page">1<!-- --></a></li><li class="next disabled"><a class="transition duration-100 bg-transparent shadow-md shadow-transparent rounded-lg hover:shadow-gray-900 hover:bg-gray-700 hover:underline hover:decoration-2 px-2 py-1 mt-1 mx-1 items-center inline-block text-base " tabindex="-1" role="button" aria-disabled="true" aria-label="Next page" rel="next"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="fill-sky-400 fill-stone-200" height="30" width="30" xmlns="http://www.w3.org/2000/svg"><path d="M10.707 17.707 16.414 12l-5.707-5.707-1.414 1.414L13.586 12l-4.293 4.293z"></path></svg></a></li></ul></div></div></div></main><div class="fixed bottom-4 right-4 drop-shadow-lg z-50 shadow-gray-900"><button><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="fill-sky-400 fill-gray-900 rounded-full bg-slate-600 hover:bg-slate-500" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M256 464c114.9 0 208-93.1 208-208S370.9 48 256 48 48 141.1 48 256s93.1 208 208 208zm0-244.5l-81.1 81.9c-7.5 7.5-19.8 7.5-27.3 0s-7.5-19.8 0-27.3l95.7-95.4c7.3-7.3 19.1-7.5 26.6-.6l94.3 94c3.8 3.8 5.7 8.7 5.7 13.7 0 4.9-1.9 9.9-5.6 13.6-7.5 7.5-19.7 7.6-27.3 0l-81-79.9z"></path></svg></button></div><footer class="bg-gray-800 mt-8 py-4 text-gray-300 drop-shadow-lg shadow-gray-900"><div class="container mx-auto flex justify-center text-sm">© 2022 Shariff Faleel</div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"slug":"2022-09-16-profiling_loading_org_files","frontmatter":{"layout":"post","comments":true,"title":"Profiling file loading times for org mode","tags":["emacs","org"],"tagline":"The loading times of files was starting to become an issue as I started switching to the 'one file per note` approach in my org-roam database. Documenting some profiling I did to see what I can do about it."},"excerpt":""},{"slug":"2022-07-29-pub-ali22_edgeselect","frontmatter":{"title":"EdgeSelect: Smartwatch Data Interaction with Minimal Screen Occlusion","date":"2022-11-07","authors":"Ali Neshati; Aaron Salo; \u003cb\u003eShariff AM Faleel\u003c/b\u003e; Ziming Li; Hai-Ning Liang; Celine Latulipe; Pourang Irani","venue":"ICMI '22 (Accepted)","type":"Conference","paperurl":"TBA","doi":"TBA","citation":"TBA","abstract":"","pdf":"/pdf/ali22_edgeselect.pdf"},"excerpt":""},{"slug":"2022-06-13-pub-alallah22_ssca","frontmatter":{"title":"SSCA: Situated Space-time Cube Analytics","date":"2022-06-13","authors":"Fouad Alallah, \u003cb\u003eShariff AM Faleel\u003c/b\u003e, Yumiko Sakamoto, Bradley Rey, Pourang Irani","venue":"EuroVis '22","type":"Conference","paperurl":"https://diglib.eg.org/handle/10.2312/evs20221088","doi":"10.2312/evs20221088","citation":"Alallah, F., Faleel, S., Sakamoto, Y., Rey, B., \u0026 Irani, P. (2022). SSCA: situated space-time cube analytics. In M. Agus, W. Aigner, \u0026 T. Hoellt, EuroVis 2022 - Short Papers (pp. ). : The Eurographics Association.","abstract":"Spatio-temporal visualization research has been capturing much attention in recent years. Space-time cube (STC) has been commonly used to visualize this data to support analytic tasks. However, the current STC visualization tools are currently not compatible with situated platforms since these tools are often designed for desktop computing. Thus, we propose a situated space-time cube analytics (SSCA) prototype that maps spatio-temporal trajectory data into the environment where the data was captured. Being situated in such an environment while exploring data can provide benefits, and further allows us to explore interaction techniques such as proxemics and embodied interaction. We are confident that with SSCA, and a new generation of augmented reality technologies, researchers can begin to better explore the potential of situated STC analytics.","pdf":"/pdf/alallah22_ssca.pdf"},"excerpt":""},{"slug":"2022-05-21-lit-mangaement","frontmatter":{"layout":"post","comments":true,"title":"Reference Management: What am I managing?","tags":["org","emacs","reference-management"],"tagline":"Documenting the features of my reference management system along with a wish list."},"excerpt":""},{"slug":"2022-05-02-oculus_setup","frontmatter":{"layout":"post","comments":true,"title":"Setting up Oculus Quest 2 for development with Unity","tags":["oculus","vr","guide"],"tagline":"Step-by-step guide to setting up oculus for development with unity."},"excerpt":""},{"slug":"2022-04-19-nextjs-gh-pages","frontmatter":{"layout":"post","comments":true,"title":"Personal website with nextjs and github pages","tags":["javascript","react","next","guide"],"tagline":"Summery of how I went about setting up my personal website which with markdown blog on github pages using nextjs."},"excerpt":""},{"slug":"2021-08-27-pub-shariff21_hpui","frontmatter":{"title":"HPUI: Hand Proximate User Interfaces for One-Handed Interactions on Head Mounted Displays","date":"2021-08-27","authors":"\u003cb\u003eShariff AM Faleel\u003c/b\u003e; Michael Gammon; Kevin Fan; Da-Yuan Huang; Wei Li; Pourang Irani","venue":"TVCG (ISMAR '21)","type":"Journal","paperurl":"https://doi.org/10.1109/TVCG.2021.3106493","doi":"10.1109/TVCG.2021.3106493","citation":"S. A. Faleel, M. Gammon, K. Fan, D. -Y. Huang, W. Li and P. Irani, \"HPUI: Hand Proximate User Interfaces for One-Handed Interactions on Head Mounted Displays,\" in IEEE Transactions on Visualization and Computer Graphics, vol. 27, no. 11, pp. 4215-4225, Nov. 2021, doi: 10.1109/TVCG.2021.3106493.","abstract":"We explore the design of Hand Proximate User Interfaces (HPUIs) for head-mounted displays (HMDs) to facilitate near-body interactions with the display directly projected on, or around the user's hand. We focus on single-handed input, while taking into consideration the hand anatomy which distorts naturally when the user interacts with the display. Through two user studies, we explore the potential for discrete as well as continuous input. For discrete input, HPUIs favor targets that are directly on the fingers (as opposed to off-finger) as they offer tactile feedback. We demonstrate that continuous interaction is also possible, and is as effective on the fingers as in the off-finger space between the index finger and thumb. We also find that with continuous input, content is more easily controlled when the interaction occurs in the vertical or horizontal axes, and less with diagonal movements. We conclude with applications and recommendations for the design of future HPUIs.","pdf":"/pdf/shariff21_hpui.pdf"},"excerpt":""},{"slug":"2021-07-06-pub-shariff21_writely","frontmatter":{"title":"Writely: Force Feedback for Non-Dominant Hand Writing Training","date":"2021-07-06","authors":"\u003cb\u003eShariff AM Faleel\u003c/b\u003e; Bibhushan Raj Joshi; Bradley Rey","venue":"WHC '21","type":"Conference","paperurl":"https://doi.org/10.1109/WHC49131.2021.9517209'","doi":"WHC49131.2021.9517209","citation":"S. A. Faleel, B. Raj Joshi and B. Rey, \"Writely: Force Feedback for Non-Dominant Hand Writing Training,\" 2021 IEEE World Haptics Conference (WHC), 2021, pp. 340-340, doi: 10.1109/WHC49131.2021.9517209.","abstract":"We propose Writely, a haptic force feedback system that uses Haply force feedback device for training non-dominant hand writing. In this work we have developed two different force feedback modalities, Guidance and Anti-Guidance. Through a preliminary exploration, our early results shed light on the potential of Anti-Guidance and a low cost, planar, haptic device specifically for writing motor skill training.","pdf":"/pdf/shariff21_writely.pdf"},"excerpt":""},{"slug":"2021-05-07-pub-ali21_bezelglide","frontmatter":{"title":"BezelGlide: Interacting with Graphs on Smartwatches with Minimal Screen Occlusion","date":"2021-05-07","authors":"Ali Neshati; Bradley Rey; \u003cb\u003eAhmed Shariff Mohommed Faleel\u003c/b\u003e; Sandra Bardot; Celine Latulipe; Pourang Irani","venue":"CHI '21","type":"Conference","paperurl":"https://doi.org/10.1145/3411764.3445201","doi":"10.1145/3411764.3445201","citation":"Ali Neshati, Bradley Rey, Ahmed Shariff Mohommed Faleel, Sandra Bardot, Celine Latulipe, and Pourang Irani. 2021. BezelGlide: Interacting with Graphs on Smartwatches with Minimal Screen Occlusion. In \u003ci\u003eProceedings of the 2021 CHI Conference on Human Factors in Computing Systems\u003c/i\u003e (\u003ci\u003eCHI '21\u003c/i\u003e). Association for Computing Machinery, New York, NY, USA, Article 501, 1–13. https://doi.org/10.1145/3411764.3445201","abstract":"Mid-air gestures have been heavily studied in HCI but with mostly younger adults (YAs). Older adults (OAs) can equally benefit from such a modality, but given their heterogeneous motor abilities, designing suitable gestures is challenging [2]. Our research specifically looks at age-related differences in hand gesture preferences between older and younger adults. This subject is important since it relates to the idea of a proper age-inclusive technological design and the means towards the successful adoption of technologies by all the layers of the population, including older adults.","pdf":"/pdf/ali21_bezelglide.pdf"},"excerpt":""},{"slug":"2021-03-29-canhap_writel_i2","frontmatter":{"layout":"post","comments":true,"title":"Writely (Part 2) - Face the kraken","tags":["course","hci"],"tagline":"Second iteration of the canhap project, where wrestle the haptic implementations on our system."},"excerpt":""},{"slug":"2021-03-12-canhap-lab3","frontmatter":{"layout":"post","comments":true,"title":"Talking with haptics","tags":["course","hci"],"tagline":"Playing with PID controllers and haply"},"excerpt":""},{"slug":"2021-03-08-canhap_writely_i1","frontmatter":{"layout":"post","comments":true,"title":"Writely (Part 1) - Into the belly of the beast","tags":["course","hci"],"tagline":"First iteration of using haply to develop a system for training writing."},"excerpt":""},{"slug":"2021-02-26-canhap-lab4","frontmatter":{"layout":"post","comments":true,"title":"PID with Haply","tags":["course","hci"],"tagline":"Playing with PID controllers and haply"},"excerpt":""},{"slug":"2021-02-05-canhap-lab2","frontmatter":{"layout":"post","comments":true,"title":"Exploring Haply","tags":["course","hci"],"tagline":"Introducing myself to using haply, processing and fisca"},"excerpt":""},{"slug":"2021-01-29-forky","frontmatter":{"layout":"post","comments":true,"title":"Make forky walk - Sketching lab","tags":["course","hci"],"tagline":"It's trash"},"excerpt":""},{"slug":"2021-01-27-org_ref_brain","frontmatter":{"layout":"post","comments":true,"title":"Using org mode for bibliography management","tags":["emacs","org","reference-management"],"tagline":"All hail emacs! All hail org-mode!"},"excerpt":""},{"slug":"2020-05-27-pub-yurii20_using_guess","frontmatter":{"title":"Using guessability framework: age-related differences in hand gesture interaction","date":"2020-05-27","authors":"Yurii Vasylkiv; Ali Neshati; \u003cb\u003eShariff AM Faleel\u003c/b\u003e; Yumiko Sakamoto; Pourang Irani","venue":"Augmented Human (AH '20)","type":"Conference","paperurl":"https://doi.org/10.1145/3396339.3396394","doi":"10.1145/3396339.3396394","citation":"Yurii Vasylkiv, Ali Neshati, Shariff A. M. Faleel, Yumiko Sakamoto, and Pourang Irani. 2020. Using guessability framework: age-related differences in hand gesture interaction. In \u003ci\u003eProceedings of the 11th Augmented Human International Conference\u003c/i\u003e (\u003ci\u003eAH '20\u003c/i\u003e). Association for Computing Machinery, New York, NY, USA, Article 24, 1–2. https://doi.org/10.1145/3396339.3396394","abstract":"Mid-air gestures have been heavily studied in HCI but with mostly younger adults (YAs). Older adults (OAs) can equally benefit from such a modality, but given their heterogeneous motor abilities, designing suitable gestures is challenging [2]. Our research specifically looks at age-related differences in hand gesture preferences between older and younger adults. This subject is important since it relates to the idea of a proper age-inclusive technological design and the means towards the successful adoption of technologies by all the layers of the population, including older adults.","pdf":"/pdf/yurii20_using_guess.pdf"},"excerpt":""},{"slug":"2020-05-27-pub-shariff20_user_gesture","frontmatter":{"title":"User Gesture Elicitation of Common Smartphone Tasks for Hand Proximate User Interfaces","date":"2020-05-27","authors":"\u003cb\u003eShariff AM Faleel\u003c/b\u003e; Michael Gammon; Yumiko Sakamoto; Carlo Menon; Pourang Irani","venue":"Augmented Human (AH '20)","type":"Conference","paperurl":"https://doi.org/10.1145/3396339.3396363","doi":"10.1145/3396339.3396363","citation":"Shariff A. M. Faleel, Michael Gammon, Yumiko Sakamoto, Carlo Menon, and Pourang Irani. 2020. User gesture elicitation of common smartphone tasks for hand proximate user interfaces. In \u003ci\u003eProceedings of the 11th Augmented Human International Conference\u003c/i\u003e (\u003ci\u003eAH '20\u003c/i\u003e). Association for Computing Machinery, New York, NY, USA, Article 6, 1–8. https://doi.org/10.1145/3396339.3396363","abstract":"The ubiquity of smartphone interactions along with the advancements made in mixed reality applications and gesture recognition present an intriguing space for novel interaction techniques using the hand as an interface. This paper explores the idea of using hand proximate user interfaces (UI), i.e. interactions with and display of interface elements on and around the hand. We conducted two user studies to gain a better understanding of the design space for such interactions. The first study identifies the possible ways in which various elements can be displayed on and around the hand in the context of common smartphone applications. We conduct a second study to build a gesture set for interactions with elements displayed on and around the hand. We contribute an analysis of the data and observations collected from the two studies, resulting in a layout set and a gesture set for interactions with hand proximate UIs.","pdf":"/pdf/shariff20_user_gesture.pdf"},"excerpt":""},{"slug":"2019-07-05-pub-shariff19_dialog_manager","frontmatter":{"title":"A Novel Dialogue Manager Model for Spoken Dialogue Systems Based on User Input Learning","date":"2019-07-05","authors":"\u003cb\u003eM.F. Ahmed Shariff\u003c/b\u003e; Ruwan D. Nawarathna","venue":"SLAAI-ICAI '18","type":"Conference","paperurl":"https://doi.org/10.1007/978-981-13-9129-3_14","doi":"10.1007/978-981-13-9129-3_14","citation":"Ahmed Shariff, M.F., Nawarathna, R.D. (2019). A Novel Dialogue Manager Model for Spoken Dialogue Systems Based on User Input Learning. In: Hemanth, J., Silva, T., Karunananda, A. (eds) Artificial Intelligence. SLAAI-ICAI 2018. Communications in Computer and Information Science, vol 890. Springer, Singapore. https://doi.org/10.1007/978-981-13-9129-3_14","abstract":"The complexity of the dialogue manager is a major issue in spoken dialogue systems. In this work, a novel dialogue manager based on user input learning is proposed to overcome this issue. In the proposed model back-end functionality is considered as a set of functions a user can trigger through the dialogue manager. It uses these functions as classes for the classification of user inputs. To maintain the context of the dialogue interactions, a context tree is used. Consequently, the model performs its task as two classification tasks to identify the function a user input may trigger and use the context to maintain the discourse of the dialogue. The model shows promising results and proves that a dialogue manager can be integrated into a spoken dialogue system much more directly with less hassle.","pdf":"/pdf/shariff19_dialog_manager.pdf"},"excerpt":""},{"slug":"2019-02-18-labeling_process","frontmatter":{"layout":"post","comments":true,"title":"The game of labeling","tags":["machine learning"],"tagline":"A summery of the labeing process I follow"},"excerpt":""},{"slug":"2019-01-08-nlp_retrospective","frontmatter":{"layout":"post","comments":true,"title":"Building a dialogue manager - A retrospective","tags":["deep learning","NLP"],"tagline":"Lesons learnt and thoughts after working on the dialogue management model"},"excerpt":""},{"slug":"2018-11-01-article_review_using_git","frontmatter":{"layout":"post","comments":true,"title":"Article review using git","tags":["Random thoughts"],"tagline":"Implementing a review system for articles using git"},"excerpt":""},{"slug":"2018-09-10-quantum_computing","frontmatter":{"layout":"post","comments":true,"title":"Quantum computing","tags":["Random thoughts"],"tagline":"A brief introduction to the basics of quantum computing."},"excerpt":""},{"slug":"2018-08-31-how-the-mind-works","frontmatter":{"layout":"post","comments":true,"title":"Steven Pinker's 'How the mind works'","tags":["Random thoughts"],"tagline":"A few ideas in the book I found interesting. (Though I don't fully understand or accept/agree with them all)"},"excerpt":""},{"slug":"2018-08-01-mlp_file_structure","frontmatter":{"layout":"post","comments":true,"title":"Practices I follow with the machine learning pipeline","tags":["deep learning"],"tagline":"While the ml-pipeline solves some of the problems I encounter, it doesn't solve all of them. Here I describe my process beyond the pipeline."},"excerpt":""},{"slug":"2018-07-26-ml-problems","frontmatter":{"layout":"post","comments":true,"title":"ML problems I run into","tags":["Random thoughts"],"tagline":"An ongoing list of problems I run into when using deep learning"},"excerpt":""},{"slug":"2018-07-17-tic-tac-toe","frontmatter":{"layout":"post","comments":true,"title":"Teaching a computer to play Tic-Tac-Toe.","tags":["Random thoughts"],"tagline":"A simple demonstration of teaching a computer to play tic-tac-toe. This is part of a demonstration made for the first year undergraduates."},"excerpt":""},{"slug":"2018-06-13-qubits-opened","frontmatter":{"layout":"post","comments":true,"title":"Opening of the qubits lab","tags":null},"excerpt":""},{"slug":"2018-06-11-Experiment-log","frontmatter":{"layout":"post","comments":true,"title":"Experiment log - How I keep track of my ML experiments","tags":["machine learning"],"tagline":"In order to reduce the clutter, I keep track of the experiments using a emacs org-mode."},"excerpt":""},{"slug":"2018-04-25-why-no-posting","frontmatter":{"layout":"post","comments":true,"title":"Why you no posting stuff?","tags":["Random thoughts"],"tagline":"Why indeed......"},"excerpt":""}]},"__N_SSG":true},"page":"/posts","query":{},"buildId":"6uFZU0TQNLkSN4GAj_HCN","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>