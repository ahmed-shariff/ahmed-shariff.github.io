{"pageProps":{"posts":[{"slug":"2022-07-29-pub-ali22_edgeselect","frontmatter":{"title":"EdgeSelect: Smartwatch Data Interaction with Minimal Screen Occlusion","date":"2022-11-07","authors":"Ali Neshati; Aaron Salo; <b>Shariff AM Faleel</b>; Ziming Li; Hai-Ning Liang; Celine Latulipe; Pourang Irani","venue":"ICMI '22 (Accepted)","type":"Conference","paperurl":"TBA","doi":"TBA","citation":"TBA","abstract":"","pdf":"/pdf/ali22_edgeselect.pdf"},"excerpt":""},{"slug":"2022-06-13-pub-alallah22_ssca","frontmatter":{"title":"SSCA: Situated Space-time Cube Analytics","date":"2022-06-13","authors":"Fouad Alallah, <b>Shariff AM Faleel</b>, Yumiko Sakamoto, Bradley Rey, Pourang Irani","venue":"EuroVis '22","type":"Conference","paperurl":"https://diglib.eg.org/handle/10.2312/evs20221088","doi":"10.2312/evs20221088","citation":"Alallah, F., Faleel, S., Sakamoto, Y., Rey, B., & Irani, P. (2022). SSCA: situated space-time cube analytics. In M. Agus, W. Aigner, & T. Hoellt, EuroVis 2022 - Short Papers (pp. ). : The Eurographics Association.","abstract":"Spatio-temporal visualization research has been capturing much attention in recent years. Space-time cube (STC) has been commonly used to visualize this data to support analytic tasks. However, the current STC visualization tools are currently not compatible with situated platforms since these tools are often designed for desktop computing. Thus, we propose a situated space-time cube analytics (SSCA) prototype that maps spatio-temporal trajectory data into the environment where the data was captured. Being situated in such an environment while exploring data can provide benefits, and further allows us to explore interaction techniques such as proxemics and embodied interaction. We are confident that with SSCA, and a new generation of augmented reality technologies, researchers can begin to better explore the potential of situated STC analytics.","pdf":"/pdf/alallah22_ssca.pdf"},"excerpt":""},{"slug":"2022-05-21-lit-mangaement","frontmatter":{"layout":"post","comments":true,"title":"Reference Management: What am I managing?","tags":["org","emacs","reference-management"],"tagline":"Documenting the features of my reference management system along with a wish list."},"excerpt":""},{"slug":"2022-05-02-oculus_setup","frontmatter":{"layout":"post","comments":true,"title":"Setting up Oculus Quest 2 for development with Unity","tags":["oculus","vr","guide"],"tagline":"Step-by-step guide to setting up oculus for development with unity."},"excerpt":""},{"slug":"2022-04-19-nextjs-gh-pages","frontmatter":{"layout":"post","comments":true,"title":"Personal website with nextjs and github pages","tags":["javascript","react","next","guide"],"tagline":"Summery of how I went about setting up my personal website which with markdown blog on github pages using nextjs."},"excerpt":""},{"slug":"2021-08-27-pub-shariff21_hpui","frontmatter":{"title":"HPUI: Hand Proximate User Interfaces for One-Handed Interactions on Head Mounted Displays","date":"2021-08-27","authors":"<b>Shariff AM Faleel</b>; Michael Gammon; Kevin Fan; Da-Yuan Huang; Wei Li; Pourang Irani","venue":"TVCG (ISMAR '21)","type":"Journal","paperurl":"https://doi.org/10.1109/TVCG.2021.3106493","doi":"10.1109/TVCG.2021.3106493","citation":"S. A. Faleel, M. Gammon, K. Fan, D. -Y. Huang, W. Li and P. Irani, \"HPUI: Hand Proximate User Interfaces for One-Handed Interactions on Head Mounted Displays,\" in IEEE Transactions on Visualization and Computer Graphics, vol. 27, no. 11, pp. 4215-4225, Nov. 2021, doi: 10.1109/TVCG.2021.3106493.","abstract":"We explore the design of Hand Proximate User Interfaces (HPUIs) for head-mounted displays (HMDs) to facilitate near-body interactions with the display directly projected on, or around the user's hand. We focus on single-handed input, while taking into consideration the hand anatomy which distorts naturally when the user interacts with the display. Through two user studies, we explore the potential for discrete as well as continuous input. For discrete input, HPUIs favor targets that are directly on the fingers (as opposed to off-finger) as they offer tactile feedback. We demonstrate that continuous interaction is also possible, and is as effective on the fingers as in the off-finger space between the index finger and thumb. We also find that with continuous input, content is more easily controlled when the interaction occurs in the vertical or horizontal axes, and less with diagonal movements. We conclude with applications and recommendations for the design of future HPUIs.","pdf":"/pdf/shariff21_hpui.pdf"},"excerpt":""},{"slug":"2021-07-06-pub-shariff21_writely","frontmatter":{"title":"Writely: Force Feedback for Non-Dominant Hand Writing Training","date":"2021-07-06","authors":"<b>Shariff AM Faleel</b>; Bibhushan Raj Joshi; Bradley Rey","venue":"WHC '21","type":"Conference","paperurl":"https://doi.org/10.1109/WHC49131.2021.9517209'","doi":"WHC49131.2021.9517209","citation":"S. A. Faleel, B. Raj Joshi and B. Rey, \"Writely: Force Feedback for Non-Dominant Hand Writing Training,\" 2021 IEEE World Haptics Conference (WHC), 2021, pp. 340-340, doi: 10.1109/WHC49131.2021.9517209.","abstract":"We propose Writely, a haptic force feedback system that uses Haply force feedback device for training non-dominant hand writing. In this work we have developed two different force feedback modalities, Guidance and Anti-Guidance. Through a preliminary exploration, our early results shed light on the potential of Anti-Guidance and a low cost, planar, haptic device specifically for writing motor skill training.","pdf":"/pdf/shariff21_writely.pdf"},"excerpt":""},{"slug":"2021-05-07-pub-ali21_bezelglide","frontmatter":{"title":"BezelGlide: Interacting with Graphs on Smartwatches with Minimal Screen Occlusion","date":"2021-05-07","authors":"Ali Neshati; Bradley Rey; <b>Ahmed Shariff Mohommed Faleel</b>; Sandra Bardot; Celine Latulipe; Pourang Irani","venue":"CHI '21","type":"Conference","paperurl":"https://doi.org/10.1145/3411764.3445201","doi":"10.1145/3411764.3445201","citation":"Ali Neshati, Bradley Rey, Ahmed Shariff Mohommed Faleel, Sandra Bardot, Celine Latulipe, and Pourang Irani. 2021. BezelGlide: Interacting with Graphs on Smartwatches with Minimal Screen Occlusion. In <i>Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</i> (<i>CHI '21</i>). Association for Computing Machinery, New York, NY, USA, Article 501, 1–13. https://doi.org/10.1145/3411764.3445201","abstract":"Mid-air gestures have been heavily studied in HCI but with mostly younger adults (YAs). Older adults (OAs) can equally benefit from such a modality, but given their heterogeneous motor abilities, designing suitable gestures is challenging [2]. Our research specifically looks at age-related differences in hand gesture preferences between older and younger adults. This subject is important since it relates to the idea of a proper age-inclusive technological design and the means towards the successful adoption of technologies by all the layers of the population, including older adults.","pdf":"/pdf/ali21_bezelglide.pdf"},"excerpt":""},{"slug":"2021-03-29-canhap_writel_i2","frontmatter":{"layout":"post","comments":true,"title":"Writely (Part 2) - Face the kraken","tags":["course","hci"],"tagline":"Second iteration of the canhap project, where wrestle the haptic implementations on our system."},"excerpt":""},{"slug":"2021-03-12-canhap-lab3","frontmatter":{"layout":"post","comments":true,"title":"Talking with haptics","tags":["course","hci"],"tagline":"Playing with PID controllers and haply"},"excerpt":""},{"slug":"2021-03-08-canhap_writely_i1","frontmatter":{"layout":"post","comments":true,"title":"Writely (Part 1) - Into the belly of the beast","tags":["course","hci"],"tagline":"First iteration of using haply to develop a system for training writing."},"excerpt":""},{"slug":"2021-02-26-canhap-lab4","frontmatter":{"layout":"post","comments":true,"title":"PID with Haply","tags":["course","hci"],"tagline":"Playing with PID controllers and haply"},"excerpt":""},{"slug":"2021-02-05-canhap-lab2","frontmatter":{"layout":"post","comments":true,"title":"Exploring Haply","tags":["course","hci"],"tagline":"Introducing myself to using haply, processing and fisca"},"excerpt":""},{"slug":"2021-01-29-forky","frontmatter":{"layout":"post","comments":true,"title":"Make forky walk - Sketching lab","tags":["course","hci"],"tagline":"It's trash"},"excerpt":""},{"slug":"2021-01-27-org_ref_brain","frontmatter":{"layout":"post","comments":true,"title":"Using org mode for bibliography management","tags":["emacs","org","reference-management"],"tagline":"All hail emacs! All hail org-mode!"},"excerpt":""},{"slug":"2020-05-27-pub-yurii20_using_guess","frontmatter":{"title":"Using guessability framework: age-related differences in hand gesture interaction","date":"2020-05-27","authors":"Yurii Vasylkiv; Ali Neshati; <b>Shariff AM Faleel</b>; Yumiko Sakamoto; Pourang Irani","venue":"Augmented Human (AH '20)","type":"Conference","paperurl":"https://doi.org/10.1145/3396339.3396394","doi":"10.1145/3396339.3396394","citation":"Yurii Vasylkiv, Ali Neshati, Shariff A. M. Faleel, Yumiko Sakamoto, and Pourang Irani. 2020. Using guessability framework: age-related differences in hand gesture interaction. In <i>Proceedings of the 11th Augmented Human International Conference</i> (<i>AH '20</i>). Association for Computing Machinery, New York, NY, USA, Article 24, 1–2. https://doi.org/10.1145/3396339.3396394","abstract":"Mid-air gestures have been heavily studied in HCI but with mostly younger adults (YAs). Older adults (OAs) can equally benefit from such a modality, but given their heterogeneous motor abilities, designing suitable gestures is challenging [2]. Our research specifically looks at age-related differences in hand gesture preferences between older and younger adults. This subject is important since it relates to the idea of a proper age-inclusive technological design and the means towards the successful adoption of technologies by all the layers of the population, including older adults.","pdf":"/pdf/yurii20_using_guess.pdf"},"excerpt":""},{"slug":"2020-05-27-pub-shariff20_user_gesture","frontmatter":{"title":"User Gesture Elicitation of Common Smartphone Tasks for Hand Proximate User Interfaces","date":"2020-05-27","authors":"<b>Shariff AM Faleel</b>; Michael Gammon; Yumiko Sakamoto; Carlo Menon; Pourang Irani","venue":"Augmented Human (AH '20)","type":"Conference","paperurl":"https://doi.org/10.1145/3396339.3396363","doi":"10.1145/3396339.3396363","citation":"Shariff A. M. Faleel, Michael Gammon, Yumiko Sakamoto, Carlo Menon, and Pourang Irani. 2020. User gesture elicitation of common smartphone tasks for hand proximate user interfaces. In <i>Proceedings of the 11th Augmented Human International Conference</i> (<i>AH '20</i>). Association for Computing Machinery, New York, NY, USA, Article 6, 1–8. https://doi.org/10.1145/3396339.3396363","abstract":"The ubiquity of smartphone interactions along with the advancements made in mixed reality applications and gesture recognition present an intriguing space for novel interaction techniques using the hand as an interface. This paper explores the idea of using hand proximate user interfaces (UI), i.e. interactions with and display of interface elements on and around the hand. We conducted two user studies to gain a better understanding of the design space for such interactions. The first study identifies the possible ways in which various elements can be displayed on and around the hand in the context of common smartphone applications. We conduct a second study to build a gesture set for interactions with elements displayed on and around the hand. We contribute an analysis of the data and observations collected from the two studies, resulting in a layout set and a gesture set for interactions with hand proximate UIs.","pdf":"/pdf/shariff20_user_gesture.pdf"},"excerpt":""},{"slug":"2019-07-05-pub-shariff19_dialog_manager","frontmatter":{"title":"A Novel Dialogue Manager Model for Spoken Dialogue Systems Based on User Input Learning","date":"2019-07-05","authors":"<b>M.F. Ahmed Shariff</b>; Ruwan D. Nawarathna","venue":"SLAAI-ICAI '18","type":"Conference","paperurl":"https://doi.org/10.1007/978-981-13-9129-3_14","doi":"10.1007/978-981-13-9129-3_14","citation":"Ahmed Shariff, M.F., Nawarathna, R.D. (2019). A Novel Dialogue Manager Model for Spoken Dialogue Systems Based on User Input Learning. In: Hemanth, J., Silva, T., Karunananda, A. (eds) Artificial Intelligence. SLAAI-ICAI 2018. Communications in Computer and Information Science, vol 890. Springer, Singapore. https://doi.org/10.1007/978-981-13-9129-3_14","abstract":"The complexity of the dialogue manager is a major issue in spoken dialogue systems. In this work, a novel dialogue manager based on user input learning is proposed to overcome this issue. In the proposed model back-end functionality is considered as a set of functions a user can trigger through the dialogue manager. It uses these functions as classes for the classification of user inputs. To maintain the context of the dialogue interactions, a context tree is used. Consequently, the model performs its task as two classification tasks to identify the function a user input may trigger and use the context to maintain the discourse of the dialogue. The model shows promising results and proves that a dialogue manager can be integrated into a spoken dialogue system much more directly with less hassle.","pdf":"/pdf/shariff19_dialog_manager.pdf"},"excerpt":""},{"slug":"2019-02-18-labeling_process","frontmatter":{"layout":"post","comments":true,"title":"The game of labeling","tags":["machine learning"],"tagline":"A summery of the labeing process I follow"},"excerpt":""},{"slug":"2019-01-08-nlp_retrospective","frontmatter":{"layout":"post","comments":true,"title":"Building a dialogue manager - A retrospective","tags":["deep learning","NLP"],"tagline":"Lesons learnt and thoughts after working on the dialogue management model"},"excerpt":""},{"slug":"2018-11-01-article_review_using_git","frontmatter":{"layout":"post","comments":true,"title":"Article review using git","tags":["Random thoughts"],"tagline":"Implementing a review system for articles using git"},"excerpt":""},{"slug":"2018-09-10-quantum_computing","frontmatter":{"layout":"post","comments":true,"title":"Quantum computing","tags":["Random thoughts"],"tagline":"A brief introduction to the basics of quantum computing."},"excerpt":""},{"slug":"2018-08-31-how-the-mind-works","frontmatter":{"layout":"post","comments":true,"title":"Steven Pinker's 'How the mind works'","tags":["Random thoughts"],"tagline":"A few ideas in the book I found interesting. (Though I don't fully understand or accept/agree with them all)"},"excerpt":""},{"slug":"2018-08-01-mlp_file_structure","frontmatter":{"layout":"post","comments":true,"title":"Practices I follow with the machine learning pipeline","tags":["deep learning"],"tagline":"While the ml-pipeline solves some of the problems I encounter, it doesn't solve all of them. Here I describe my process beyond the pipeline."},"excerpt":""},{"slug":"2018-07-26-ml-problems","frontmatter":{"layout":"post","comments":true,"title":"ML problems I run into","tags":["Random thoughts"],"tagline":"An ongoing list of problems I run into when using deep learning"},"excerpt":""},{"slug":"2018-07-17-tic-tac-toe","frontmatter":{"layout":"post","comments":true,"title":"Teaching a computer to play Tic-Tac-Toe.","tags":["Random thoughts"],"tagline":"A simple demonstration of teaching a computer to play tic-tac-toe. This is part of a demonstration made for the first year undergraduates."},"excerpt":""},{"slug":"2018-06-13-qubits-opened","frontmatter":{"layout":"post","comments":true,"title":"Opening of the qubits lab","tags":null},"excerpt":""},{"slug":"2018-06-11-Experiment-log","frontmatter":{"layout":"post","comments":true,"title":"Experiment log - How I keep track of my ML experiments","tags":["machine learning"],"tagline":"In order to reduce the clutter, I keep track of the experiments using a emacs org-mode."},"excerpt":""},{"slug":"2018-04-25-why-no-posting","frontmatter":{"layout":"post","comments":true,"title":"Why you no posting stuff?","tags":["Random thoughts"],"tagline":"Why indeed......"},"excerpt":""}]},"__N_SSG":true}