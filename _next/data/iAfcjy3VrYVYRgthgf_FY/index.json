{"pageProps":{"posts":[{"slug":"2023-03-04-faleel23_t_force","frontmatter":{"title":"T-Force: Exploring the Use of Typing Force for Three State Virtual Keyboards","date":"2023-04-23","authors":"<b>Shariff AM Faleel</b>, Yishuo Liu, Roya A Cody, Bradley Rey, Linghao Du, Jiangyue Yu, Da-Yuan Huang, Pourang Irani, Wei Li","venue":"CHI '23","type":"Conference","paperurl":null,"doi":"10.1145/3536221.3556586","citation":"","abstract":" Three state virtual keyboards which differentiate contact events between released, touched, and pressed states have the potential to improve overall typing experience and reduce the gap between virtual keyboards and physical keyboards. Incorporating force sensitivity, three-state virtual keyboards can utilize a force threshold to better classify a contact event. However, our limited knowledge of how force plays a role during typing on virtual keyboards limits further progress. Through a series of studies we observe that using a uniform threshold is not an optimal approach. Furthermore, the force being applied while typing varies significantly across the keys and among participants. As such, we propose three different approaches to further improve the uniform threshold. We show that a carefully selected non-uniform threshold function could be sufficient in delineating typing events on a three-state keyboard. Finally, we conclude our work with lessons learned, suggestion for future improvements, and comparisons with current methods available.","pdf":"/pdf/faleel23_t_force.pdf"},"excerpt":""},{"slug":"2022-09-18-profiling_loading_org_files-2","frontmatter":{"layout":"post","comments":true,"title":"Profiling file loading times for org mode (part 2)","tags":["emacs","org"],"tagline":"Trying to figure out why the load times with my config is much higher."},"excerpt":""},{"slug":"2022-09-16-profiling_loading_org_files","frontmatter":{"layout":"post","comments":true,"title":"Profiling file loading times for org mode","tags":["emacs","org"],"tagline":"The loading times of files was starting to become an issue as I started switching to the 'one file per note` approach in my org-roam database. Documenting some profiling I did to see what I can do about it."},"excerpt":""},{"slug":"2022-07-29-pub-ali22_edgeselect","frontmatter":{"title":"EdgeSelect: Smartwatch Data Interaction with Minimal Screen Occlusion","date":"2022-11-07","authors":"Ali Neshati; Aaron Salo; <b>Shariff AM Faleel</b>; Ziming Li; Hai-Ning Liang; Celine Latulipe; Pourang Irani","venue":"ICMI '22","type":"Conference","paperurl":"https://dl.acm.org/doi/10.1145/3536221.3556586","doi":"10.1145/3536221.3556586","citation":"Ali Neshati, Aaron Salo, Shariff Am Faleel, Ziming Li, Hai-Ning Liang, Celine Latulipe, and Pourang Irani. 2022. EdgeSelect: Smartwatch Data Interaction with Minimal Screen Occlusion. In Proceedings of the 2022 International Conference on Multimodal Interaction (ICMI '22). Association for Computing Machinery, New York, NY, USA, 288–298. https://doi.org/10.1145/3536221.3556586","abstract":"We present EdgeSelect, a linear target selection interaction technique that utilizes a small portion of the smartwatch display, explicitly designed to mitigate the ‘fat finger’ and screen occlusion problems, two of the most common and well-known challenges when interacting with small displays. To design our technique, we first conducted a user study to answer which segments of the smartwatch display have the least screen occlusion while users are interacting with it. We use results from the first experiment to introduce EdgeSelect, a three-layer non-linear interaction technique, which can be used to interact with multiple co-adjacent graphs on the smartwatch by using a region that is the least prone to finger occlusion. In a second experiment, we explore the density limits of the targets possible with EdgeSelect. Finally, we demonstrate the generalizability of EdgeSelect to interact with various types of content.","pdf":"/pdf/ali22_edgeselect.pdf"},"excerpt":""},{"slug":"2022-06-13-pub-alallah22_ssca","frontmatter":{"title":"SSCA: Situated Space-time Cube Analytics","date":"2022-06-13","authors":"Fouad Alallah, <b>Shariff AM Faleel</b>, Yumiko Sakamoto, Bradley Rey, Pourang Irani","venue":"EuroVis '22","type":"Conference","paperurl":"https://diglib.eg.org/handle/10.2312/evs20221088","doi":"10.2312/evs20221088","citation":"Alallah, F., Faleel, S., Sakamoto, Y., Rey, B., & Irani, P. (2022). SSCA: situated space-time cube analytics. In M. Agus, W. Aigner, & T. Hoellt, EuroVis 2022 - Short Papers (pp. ). : The Eurographics Association.","abstract":"Spatio-temporal visualization research has been capturing much attention in recent years. Space-time cube (STC) has been commonly used to visualize this data to support analytic tasks. However, the current STC visualization tools are currently not compatible with situated platforms since these tools are often designed for desktop computing. Thus, we propose a situated space-time cube analytics (SSCA) prototype that maps spatio-temporal trajectory data into the environment where the data was captured. Being situated in such an environment while exploring data can provide benefits, and further allows us to explore interaction techniques such as proxemics and embodied interaction. We are confident that with SSCA, and a new generation of augmented reality technologies, researchers can begin to better explore the potential of situated STC analytics.","pdf":"/pdf/alallah22_ssca.pdf"},"excerpt":""}]},"__N_SSG":true}