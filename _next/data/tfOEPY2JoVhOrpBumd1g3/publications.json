{"pageProps":{"publications":[{"slug":"2021-08-27-shariff21_hpui","frontmatter":{"title":"HPUI: Hand Proximate User Interfaces for One-Handed Interactions on Head Mounted Displays","date":"2021-08-27","authors":"<b>Shariff AM Faleel</b>; Michael Gammon; Kevin Fan; Da-Yuan Huang; Wei Li; Pourang Irani","venue":"TVCG","type":"Journal","paperurl":"https://doi.org/10.1109/TVCG.2021.3106493","doi":"10.1109/TVCG.2021.3106493","citation":"S. A. Faleel, M. Gammon, K. Fan, D. -Y. Huang, W. Li and P. Irani, \"HPUI: Hand Proximate User Interfaces for One-Handed Interactions on Head Mounted Displays,\" in IEEE Transactions on Visualization and Computer Graphics, vol. 27, no. 11, pp. 4215-4225, Nov. 2021, doi: 10.1109/TVCG.2021.3106493.","abstract":"We explore the design of Hand Proximate User Interfaces (HPUIs) for head-mounted displays (HMDs) to facilitate near-body interactions with the display directly projected on, or around the user's hand. We focus on single-handed input, while taking into consideration the hand anatomy which distorts naturally when the user interacts with the display. Through two user studies, we explore the potential for discrete as well as continuous input. For discrete input, HPUIs favor targets that are directly on the fingers (as opposed to off-finger) as they offer tactile feedback. We demonstrate that continuous interaction is also possible, and is as effective on the fingers as in the off-finger space between the index finger and thumb. We also find that with continuous input, content is more easily controlled when the interaction occurs in the vertical or horizontal axes, and less with diagonal movements. We conclude with applications and recommendations for the design of future HPUIs.","pdf":"/pdf/shariff21_hpui.pdf"},"excerpt":""},{"slug":"2021-07-06-shariff21_writely","frontmatter":{"title":"Writely: Force Feedback for Non-Dominant Hand Writing Training","date":"2021-07-06","authors":"<b>Shariff AM Faleel</b>; Bibhushan Raj Joshi; Bradley Rey","venue":"WHC '18","type":"Conference","paperurl":"https://doi.org/10.1109/WHC49131.2021.9517209'","doi":"WHC49131.2021.9517209","citation":"S. A. Faleel, B. Raj Joshi and B. Rey, \"Writely: Force Feedback for Non-Dominant Hand Writing Training,\" 2021 IEEE World Haptics Conference (WHC), 2021, pp. 340-340, doi: 10.1109/WHC49131.2021.9517209.","abstract":"We propose Writely, a haptic force feedback system that uses Haply force feedback device for training non-dominant hand writing. In this work we have developed two different force feedback modalities, Guidance and Anti-Guidance. Through a preliminary exploration, our early results shed light on the potential of Anti-Guidance and a low cost, planar, haptic device specifically for writing motor skill training.","pdf":"/pdf/shariff21_writely.pdf"},"excerpt":""},{"slug":"2021-05-07-ali21_bezelglide","frontmatter":{"title":"BezelGlide: Interacting with Graphs on Smartwatches with Minimal Screen Occlusion","date":"2021-05-07","authors":"Ali Neshati; Bradley Rey; <b>Ahmed Shariff Mohommed Faleel</b>; Sandra Bardot; Celine Latulipe; Pourang Irani","venue":"CHI '21","type":"Conference","paperurl":"https://doi.org/10.1145/3411764.3445201","doi":"10.1145/3411764.3445201","citation":"Ali Neshati, Bradley Rey, Ahmed Shariff Mohommed Faleel, Sandra Bardot, Celine Latulipe, and Pourang Irani. 2021. BezelGlide: Interacting with Graphs on Smartwatches with Minimal Screen Occlusion. In <i>Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</i> (<i>CHI '21</i>). Association for Computing Machinery, New York, NY, USA, Article 501, 1–13. https://doi.org/10.1145/3411764.3445201","abstract":"Mid-air gestures have been heavily studied in HCI but with mostly younger adults (YAs). Older adults (OAs) can equally benefit from such a modality, but given their heterogeneous motor abilities, designing suitable gestures is challenging [2]. Our research specifically looks at age-related differences in hand gesture preferences between older and younger adults. This subject is important since it relates to the idea of a proper age-inclusive technological design and the means towards the successful adoption of technologies by all the layers of the population, including older adults.","pdf":"/pdf/ali21_bezelglide.pdf"},"excerpt":""},{"slug":"2020-05-27-yurii20_using_guess","frontmatter":{"title":"Using guessability framework: age-related differences in hand gesture interaction","date":"2020-05-27","authors":"Yurii Vasylkiv; Ali Neshati; <b>Shariff AM Faleel</b>; Yumiko Sakamoto; Pourang Irani","venue":"Augmented Human (AH '20)","type":"Conference","paperurl":"https://doi.org/10.1145/3396339.3396394","doi":"10.1145/3396339.3396394","citation":"Yurii Vasylkiv, Ali Neshati, Shariff A. M. Faleel, Yumiko Sakamoto, and Pourang Irani. 2020. Using guessability framework: age-related differences in hand gesture interaction. In <i>Proceedings of the 11th Augmented Human International Conference</i> (<i>AH '20</i>). Association for Computing Machinery, New York, NY, USA, Article 24, 1–2. https://doi.org/10.1145/3396339.3396394","abstract":"Mid-air gestures have been heavily studied in HCI but with mostly younger adults (YAs). Older adults (OAs) can equally benefit from such a modality, but given their heterogeneous motor abilities, designing suitable gestures is challenging [2]. Our research specifically looks at age-related differences in hand gesture preferences between older and younger adults. This subject is important since it relates to the idea of a proper age-inclusive technological design and the means towards the successful adoption of technologies by all the layers of the population, including older adults.","pdf":"/pdf/yurii20_using_guess.pdf"},"excerpt":""},{"slug":"2020-05-27-shariff20_user_gesture","frontmatter":{"title":"User Gesture Elicitation of Common Smartphone Tasks for Hand Proximate User Interfaces","date":"2020-05-27","authors":"<b>Shariff AM Faleel</b>; Michael Gammon; Yumiko Sakamoto; Carlo Menon; Pourang Irani","venue":"Augmented Human (AH '20)","type":"Conference","paperurl":"https://doi.org/10.1145/3396339.3396363","doi":"10.1145/3396339.3396363","citation":"Shariff A. M. Faleel, Michael Gammon, Yumiko Sakamoto, Carlo Menon, and Pourang Irani. 2020. User gesture elicitation of common smartphone tasks for hand proximate user interfaces. In <i>Proceedings of the 11th Augmented Human International Conference</i> (<i>AH '20</i>). Association for Computing Machinery, New York, NY, USA, Article 6, 1–8. https://doi.org/10.1145/3396339.3396363","abstract":"The ubiquity of smartphone interactions along with the advancements made in mixed reality applications and gesture recognition present an intriguing space for novel interaction techniques using the hand as an interface. This paper explores the idea of using hand proximate user interfaces (UI), i.e. interactions with and display of interface elements on and around the hand. We conducted two user studies to gain a better understanding of the design space for such interactions. The first study identifies the possible ways in which various elements can be displayed on and around the hand in the context of common smartphone applications. We conduct a second study to build a gesture set for interactions with elements displayed on and around the hand. We contribute an analysis of the data and observations collected from the two studies, resulting in a layout set and a gesture set for interactions with hand proximate UIs.","pdf":"/pdf/shariff20_user_gesture.pdf"},"excerpt":""},{"slug":"2019-07-05-shariff19_dialog_manager","frontmatter":{"title":"A Novel Dialogue Manager Model for Spoken Dialogue Systems Based on User Input Learning","date":"2019-07-05","authors":"<b>M.F. Ahmed Shariff</b>; Ruwan D. Nawarathna","venue":"SLAAI-ICAI '18","type":"Conference","paperurl":"https://doi.org/10.1007/978-981-13-9129-3_14","doi":"10.1007/978-981-13-9129-3_14","citation":"Ahmed Shariff, M.F., Nawarathna, R.D. (2019). A Novel Dialogue Manager Model for Spoken Dialogue Systems Based on User Input Learning. In: Hemanth, J., Silva, T., Karunananda, A. (eds) Artificial Intelligence. SLAAI-ICAI 2018. Communications in Computer and Information Science, vol 890. Springer, Singapore. https://doi.org/10.1007/978-981-13-9129-3_14","abstract":"The complexity of the dialogue manager is a major issue in spoken dialogue systems. In this work, a novel dialogue manager based on user input learning is proposed to overcome this issue. In the proposed model back-end functionality is considered as a set of functions a user can trigger through the dialogue manager. It uses these functions as classes for the classification of user inputs. To maintain the context of the dialogue interactions, a context tree is used. Consequently, the model performs its task as two classification tasks to identify the function a user input may trigger and use the context to maintain the discourse of the dialogue. The model shows promising results and proves that a dialogue manager can be integrated into a spoken dialogue system much more directly with less hassle.","pdf":"/pdf/shariff19_dialog_manager.pdf"},"excerpt":""}]},"__N_SSG":true}