{"pageProps":{"posts":[{"slug":"2023-07-10_pub-holfeld23_eval_desig_study","frontmatter":{"title":"Evaluating design guidelines for hand proximate user interfaces","date":"2023-07-10","authors":"Francisco Perella-Holfeld, <b>Shariff AM Faleel</b>, Pourang Irani","venue":"DIS '23","type":"Conference","paperurl":"https://dl.acm.org/doi/10.1145/3544548.3580915","doi":"10.1145/3563657.3596117","citation":"Francisco Perella-Holfeld, Shariff AM Faleel, and Pourang Irani. 2023. Evaluating design guidelines for hand proximate user interfaces. In Proceedings of the 2023 ACM Designing Interactive Systems Conference (DIS '23). Association for Computing Machinery, New York, NY, USA, 1159–1173. https://doi.org/10.1145/3563657.3596117","abstract":"Our study investigates the design practices of Hand-Proximate User Interfaces (HPUI) which are displayed on and around a user’s hand in a head-mounted display (HMD). Specifically, we examine one-handed inputs where the main mode of interaction is thumb-to-finger contact. Our focus is on the user interface (UI) design of these displays, and we aim to develop design guidelines and heuristics for this novel design space. To achieve this, we conducted a participatory design study involving 15 participants who provided feedback on 120 different design examples, as well as their thoughts surrounding the HPUI design. Participants favored designs that were ergonomically comfortable and flexible, and those that provided clear visibility regardless of hand positioning. Based on this feedback, we developed 7 design guidelines for Hand Proximate User Interfaces. In applying these guidelines we find that common application interfaces can easily be accommodated using HPUI for use on head-mounted displays.","pdf":"https://dl.acm.org/doi/10.1145/3563657.3596117?cid=99659534363","thumbnail":"/assets/2023-07-08/TeaserFigure.png","thumbnailDescription":"These 16 hand-proximate user interfaces serve as examples to help participants understand the possible designs they can create. The interfaces are organized into different rows, each representing a specific application. For instance, the third row depicts a map application, where the first three columns exhibit distinct map navigation or display styles. The first column demonstrates a detached display with joystick control, the second features a touchpad swipe control, and the third showcases a continuous display and combined input surface. The fourth column portrays a submenu that provides additional options, such as inputting directions"},"excerpt":""},{"slug":"2023-03-04-pub-faleel23_t_force","frontmatter":{"title":"T-Force: Exploring the Use of Typing Force for Three State Virtual Keyboards","date":"2023-04-23","authors":"<b>Shariff AM Faleel</b>, Yishuo Liu, Roya A Cody, Bradley Rey, Linghao Du, Jiangyue Yu, Da-Yuan Huang, Pourang Irani, Wei Li","venue":"CHI '23","type":"Conference","paperurl":"https://dl.acm.org/doi/10.1145/3544548.3580915","doi":"10.1145/3544548.3580915","citation":"Shariff AM Faleel, Yishuo Liu, Roya A Cody, Bradley Rey, Linghao Du, Jiangyue Yu, Da-Yuan Huang, Pourang Irani, and Wei Li. 2023. T-Force: Exploring the Use of Typing Force for Three State Virtual Keyboards. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23). Association for Computing Machinery, New York, NY, USA, Article 723, 1–15. https://doi.org/10.1145/3544548.3580915","abstract":" Three state virtual keyboards which differentiate contact events between released, touched, and pressed states have the potential to improve overall typing experience and reduce the gap between virtual keyboards and physical keyboards. Incorporating force sensitivity, three-state virtual keyboards can utilize a force threshold to better classify a contact event. However, our limited knowledge of how force plays a role during typing on virtual keyboards limits further progress. Through a series of studies we observe that using a uniform threshold is not an optimal approach. Furthermore, the force being applied while typing varies significantly across the keys and among participants. As such, we propose three different approaches to further improve the uniform threshold. We show that a carefully selected non-uniform threshold function could be sufficient in delineating typing events on a three-state keyboard. Finally, we conclude our work with lessons learned, suggestion for future improvements, and comparisons with current methods available.","pdf":"https://dl.acm.org/doi/10.1145/3544548.3580915?cid=99659534363"},"excerpt":""},{"slug":"2022-09-18-profiling_loading_org_files-2","frontmatter":{"layout":"post","comments":true,"title":"Profiling file loading times for org mode (part 2)","tags":["emacs","org"],"tagline":"Trying to figure out why the load times with my config is much higher."},"excerpt":""},{"slug":"2022-09-16-profiling_loading_org_files","frontmatter":{"layout":"post","comments":true,"title":"Profiling file loading times for org mode","tags":["emacs","org"],"tagline":"The loading times of files was starting to become an issue as I started switching to the 'one file per note` approach in my org-roam database. Documenting some profiling I did to see what I can do about it."},"excerpt":""},{"slug":"2022-07-29-pub-ali22_edgeselect","frontmatter":{"title":"EdgeSelect: Smartwatch Data Interaction with Minimal Screen Occlusion","date":"2022-11-07","authors":"Ali Neshati; Aaron Salo; <b>Shariff AM Faleel</b>; Ziming Li; Hai-Ning Liang; Celine Latulipe; Pourang Irani","venue":"ICMI '22","type":"Conference","paperurl":"https://dl.acm.org/doi/10.1145/3536221.3556586","doi":"10.1145/3536221.3556586","citation":"Ali Neshati, Aaron Salo, Shariff Am Faleel, Ziming Li, Hai-Ning Liang, Celine Latulipe, and Pourang Irani. 2022. EdgeSelect: Smartwatch Data Interaction with Minimal Screen Occlusion. In Proceedings of the 2022 International Conference on Multimodal Interaction (ICMI '22). Association for Computing Machinery, New York, NY, USA, 288–298. https://doi.org/10.1145/3536221.3556586","abstract":"We present EdgeSelect, a linear target selection interaction technique that utilizes a small portion of the smartwatch display, explicitly designed to mitigate the ‘fat finger’ and screen occlusion problems, two of the most common and well-known challenges when interacting with small displays. To design our technique, we first conducted a user study to answer which segments of the smartwatch display have the least screen occlusion while users are interacting with it. We use results from the first experiment to introduce EdgeSelect, a three-layer non-linear interaction technique, which can be used to interact with multiple co-adjacent graphs on the smartwatch by using a region that is the least prone to finger occlusion. In a second experiment, we explore the density limits of the targets possible with EdgeSelect. Finally, we demonstrate the generalizability of EdgeSelect to interact with various types of content.","pdf":"https://dl.acm.org/doi/10.1145/3536221.3556586?cid=99659534363"},"excerpt":""},{"slug":"2022-06-13-pub-alallah22_ssca","frontmatter":{"title":"SSCA: Situated Space-time Cube Analytics","date":"2022-06-13","authors":"Fouad Alallah, <b>Shariff AM Faleel</b>, Yumiko Sakamoto, Bradley Rey, Pourang Irani","venue":"EuroVis '22","type":"Conference","paperurl":"https://diglib.eg.org/handle/10.2312/evs20221088","doi":"10.2312/evs20221088","citation":"Alallah, F., Faleel, S., Sakamoto, Y., Rey, B., & Irani, P. (2022). SSCA: situated space-time cube analytics. In M. Agus, W. Aigner, & T. Hoellt, EuroVis 2022 - Short Papers (pp. ). : The Eurographics Association.","abstract":"Spatio-temporal visualization research has been capturing much attention in recent years. Space-time cube (STC) has been commonly used to visualize this data to support analytic tasks. However, the current STC visualization tools are currently not compatible with situated platforms since these tools are often designed for desktop computing. Thus, we propose a situated space-time cube analytics (SSCA) prototype that maps spatio-temporal trajectory data into the environment where the data was captured. Being situated in such an environment while exploring data can provide benefits, and further allows us to explore interaction techniques such as proxemics and embodied interaction. We are confident that with SSCA, and a new generation of augmented reality technologies, researchers can begin to better explore the potential of situated STC analytics.","pdf":"http://hci.cs.umanitoba.ca/assets/publication_files/025-029.pdf"},"excerpt":""},{"slug":"2022-05-21-lit-mangaement","frontmatter":{"layout":"post","comments":true,"title":"Reference Management: What am I managing?","tags":["org","emacs","reference-management"],"tagline":"Documenting the features of my reference management system along with a wish list."},"excerpt":""},{"slug":"2022-05-02-oculus_setup","frontmatter":{"layout":"post","comments":true,"title":"Setting up Oculus Quest 2 for development with Unity","tags":["oculus","vr","guide"],"tagline":"Step-by-step guide to setting up oculus for development with unity."},"excerpt":""},{"slug":"2022-04-19-nextjs-gh-pages","frontmatter":{"layout":"post","comments":true,"title":"Personal website with nextjs and github pages","tags":["javascript","react","next","guide"],"tagline":"Summery of how I went about setting up my personal website which with markdown blog on github pages using nextjs."},"excerpt":""},{"slug":"2021-08-27-pub-shariff21_hpui","frontmatter":{"title":"HPUI: Hand Proximate User Interfaces for One-Handed Interactions on Head Mounted Displays","date":"2021-08-27","authors":"<b>Shariff AM Faleel</b>; Michael Gammon; Kevin Fan; Da-Yuan Huang; Wei Li; Pourang Irani","venue":"TVCG (ISMAR '21)","type":"Journal","paperurl":"https://doi.org/10.1109/TVCG.2021.3106493","doi":"10.1109/TVCG.2021.3106493","citation":"S. A. Faleel, M. Gammon, K. Fan, D. -Y. Huang, W. Li and P. Irani, \"HPUI: Hand Proximate User Interfaces for One-Handed Interactions on Head Mounted Displays,\" in IEEE Transactions on Visualization and Computer Graphics, vol. 27, no. 11, pp. 4215-4225, Nov. 2021, doi: 10.1109/TVCG.2021.3106493.","abstract":"We explore the design of Hand Proximate User Interfaces (HPUIs) for head-mounted displays (HMDs) to facilitate near-body interactions with the display directly projected on, or around the user's hand. We focus on single-handed input, while taking into consideration the hand anatomy which distorts naturally when the user interacts with the display. Through two user studies, we explore the potential for discrete as well as continuous input. For discrete input, HPUIs favor targets that are directly on the fingers (as opposed to off-finger) as they offer tactile feedback. We demonstrate that continuous interaction is also possible, and is as effective on the fingers as in the off-finger space between the index finger and thumb. We also find that with continuous input, content is more easily controlled when the interaction occurs in the vertical or horizontal axes, and less with diagonal movements. We conclude with applications and recommendations for the design of future HPUIs.","pdf":"/pdfs/faleel21_hpui.pdf"},"excerpt":""},{"slug":"2021-07-06-pub-shariff21_writely","frontmatter":{"title":"Writely: Force Feedback for Non-Dominant Hand Writing Training","date":"2021-07-06","authors":"<b>Shariff AM Faleel</b>; Bibhushan Raj Joshi; Bradley Rey","venue":"WHC '21","type":"Conference","paperurl":"https://doi.org/10.1109/WHC49131.2021.9517209","doi":"WHC49131.2021.9517209","citation":"S. A. Faleel, B. Raj Joshi and B. Rey, \"Writely: Force Feedback for Non-Dominant Hand Writing Training,\" 2021 IEEE World Haptics Conference (WHC), 2021, pp. 340-340, doi: 10.1109/WHC49131.2021.9517209.","abstract":"We propose Writely, a haptic force feedback system that uses Haply force feedback device for training non-dominant hand writing. In this work we have developed two different force feedback modalities, Guidance and Anti-Guidance. Through a preliminary exploration, our early results shed light on the potential of Anti-Guidance and a low cost, planar, haptic device specifically for writing motor skill training.","pdf":"/pdfs/faleel21_writel.pdf"},"excerpt":""},{"slug":"2021-05-07-pub-ali21_bezelglide","frontmatter":{"title":"BezelGlide: Interacting with Graphs on Smartwatches with Minimal Screen Occlusion","date":"2021-05-07","authors":"Ali Neshati; Bradley Rey; <b>Ahmed Shariff Mohommed Faleel</b>; Sandra Bardot; Celine Latulipe; Pourang Irani","venue":"CHI '21","type":"Conference","paperurl":"https://doi.org/10.1145/3411764.3445201","doi":"10.1145/3411764.3445201","citation":"Ali Neshati, Bradley Rey, Ahmed Shariff Mohommed Faleel, Sandra Bardot, Celine Latulipe, and Pourang Irani. 2021. BezelGlide: Interacting with Graphs on Smartwatches with Minimal Screen Occlusion. In <i>Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</i> (<i>CHI '21</i>). Association for Computing Machinery, New York, NY, USA, Article 501, 1–13. https://doi.org/10.1145/3411764.3445201","abstract":"We present BezelGlide, a novel suite of bezel interaction techniques, designed to minimize screen occlusion and ‘fat finger’ effects, when interacting with common graphs on smartwatches. To explore the design of BezelGlide, we conducted two user studies. First, we quantified the amount of screen occlusion experienced when interacting with the smartwatch bezel. Next, we designed two techniques that involve gliding the finger along the smartwatch bezel for graph interaction. Full BezelGlide (FBG) and Partial BezelGlide (PBG), use the full or a portion of the bezel, respectively, to reduce screen occlusion while scanning a line chart for data. In the common value detection task, we find that PBG outperforms FBG and Shift, a touchscreen occlusion-free technique, both quantitatively and subjectively, also while mobile. We finally illustrate the generzability potential of PBG to interact with common graph types making it a valuable interaction technique for smartwatch users.","pdf":"/pdfs/neshati21_bezel.pdf"},"excerpt":""},{"slug":"2021-03-29-canhap_writel_i2","frontmatter":{"layout":"post","comments":true,"title":"Writely (Part 2) - Face the kraken","tags":["course","hci"],"tagline":"Second iteration of the canhap project, where wrestle the haptic implementations on our system."},"excerpt":""},{"slug":"2021-03-12-canhap-lab3","frontmatter":{"layout":"post","comments":true,"title":"Talking with haptics","tags":["course","hci"],"tagline":"Playing with PID controllers and haply"},"excerpt":""},{"slug":"2021-03-08-canhap_writely_i1","frontmatter":{"layout":"post","comments":true,"title":"Writely (Part 1) - Into the belly of the beast","tags":["course","hci"],"tagline":"First iteration of using haply to develop a system for training writing."},"excerpt":""},{"slug":"2021-02-26-canhap-lab4","frontmatter":{"layout":"post","comments":true,"title":"PID with Haply","tags":["course","hci"],"tagline":"Playing with PID controllers and haply"},"excerpt":""},{"slug":"2021-02-05-canhap-lab2","frontmatter":{"layout":"post","comments":true,"title":"Exploring Haply","tags":["course","hci"],"tagline":"Introducing myself to using haply, processing and fisca"},"excerpt":""},{"slug":"2021-01-29-forky","frontmatter":{"layout":"post","comments":true,"title":"Make forky walk - Sketching lab","tags":["course","hci"],"tagline":"It's trash"},"excerpt":""},{"slug":"2021-01-27-org_ref_brain","frontmatter":{"layout":"post","comments":true,"title":"Using org mode for bibliography management","tags":["emacs","org","reference-management"],"tagline":"All hail emacs! All hail org-mode!"},"excerpt":""},{"slug":"2020-05-27-pub-yurii20_using_guess","frontmatter":{"title":"Using guessability framework: age-related differences in hand gesture interaction","date":"2020-05-27","authors":"Yurii Vasylkiv; Ali Neshati; <b>Shariff AM Faleel</b>; Yumiko Sakamoto; Pourang Irani","venue":"Augmented Human (AH '20)","type":"Conference","paperurl":"https://doi.org/10.1145/3396339.3396394","doi":"10.1145/3396339.3396394","citation":"Yurii Vasylkiv, Ali Neshati, Shariff A. M. Faleel, Yumiko Sakamoto, and Pourang Irani. 2020. Using guessability framework: age-related differences in hand gesture interaction. In <i>Proceedings of the 11th Augmented Human International Conference</i> (<i>AH '20</i>). Association for Computing Machinery, New York, NY, USA, Article 24, 1–2. https://doi.org/10.1145/3396339.3396394","abstract":"Mid-air gestures have been heavily studied in HCI but with mostly younger adults (YAs). Older adults (OAs) can equally benefit from such a modality, but given their heterogeneous motor abilities, designing suitable gestures is challenging [2]. Our research specifically looks at age-related differences in hand gesture preferences between older and younger adults. This subject is important since it relates to the idea of a proper age-inclusive technological design and the means towards the successful adoption of technologies by all the layers of the population, including older adults.","pdf":"https://dl.acm.org/doi/10.1145/3396339.3396394?cid=99659534363"},"excerpt":""},{"slug":"2020-05-27-pub-shariff20_user_gesture","frontmatter":{"title":"User Gesture Elicitation of Common Smartphone Tasks for Hand Proximate User Interfaces","date":"2020-05-27","authors":"<b>Shariff AM Faleel</b>; Michael Gammon; Yumiko Sakamoto; Carlo Menon; Pourang Irani","venue":"Augmented Human (AH '20)","type":"Conference","paperurl":"https://doi.org/10.1145/3396339.3396363","doi":"10.1145/3396339.3396363","citation":"Shariff A. M. Faleel, Michael Gammon, Yumiko Sakamoto, Carlo Menon, and Pourang Irani. 2020. User gesture elicitation of common smartphone tasks for hand proximate user interfaces. In <i>Proceedings of the 11th Augmented Human International Conference</i> (<i>AH '20</i>). Association for Computing Machinery, New York, NY, USA, Article 6, 1–8. https://doi.org/10.1145/3396339.3396363","abstract":"The ubiquity of smartphone interactions along with the advancements made in mixed reality applications and gesture recognition present an intriguing space for novel interaction techniques using the hand as an interface. This paper explores the idea of using hand proximate user interfaces (UI), i.e. interactions with and display of interface elements on and around the hand. We conducted two user studies to gain a better understanding of the design space for such interactions. The first study identifies the possible ways in which various elements can be displayed on and around the hand in the context of common smartphone applications. We conduct a second study to build a gesture set for interactions with elements displayed on and around the hand. We contribute an analysis of the data and observations collected from the two studies, resulting in a layout set and a gesture set for interactions with hand proximate UIs.","pdf":"https://dl.acm.org/doi/10.1145/3396339.3396363?cid=99659534363"},"excerpt":""},{"slug":"2019-07-05-pub-shariff19_dialog_manager","frontmatter":{"title":"A Novel Dialogue Manager Model for Spoken Dialogue Systems Based on User Input Learning","date":"2019-07-05","authors":"<b>M.F. Ahmed Shariff</b>; Ruwan D. Nawarathna","venue":"SLAAI-ICAI '18","type":"Conference","paperurl":"https://doi.org/10.1007/978-981-13-9129-3_14","doi":"10.1007/978-981-13-9129-3_14","citation":"Ahmed Shariff, M.F., Nawarathna, R.D. (2019). A Novel Dialogue Manager Model for Spoken Dialogue Systems Based on User Input Learning. In: Hemanth, J., Silva, T., Karunananda, A. (eds) Artificial Intelligence. SLAAI-ICAI 2018. Communications in Computer and Information Science, vol 890. Springer, Singapore. https://doi.org/10.1007/978-981-13-9129-3_14","abstract":"The complexity of the dialogue manager is a major issue in spoken dialogue systems. In this work, a novel dialogue manager based on user input learning is proposed to overcome this issue. In the proposed model back-end functionality is considered as a set of functions a user can trigger through the dialogue manager. It uses these functions as classes for the classification of user inputs. To maintain the context of the dialogue interactions, a context tree is used. Consequently, the model performs its task as two classification tasks to identify the function a user input may trigger and use the context to maintain the discourse of the dialogue. The model shows promising results and proves that a dialogue manager can be integrated into a spoken dialogue system much more directly with less hassle.","pdf":"/pdf/shariff19_dialog_manager.pdf"},"excerpt":""},{"slug":"2019-02-18-labeling_process","frontmatter":{"layout":"post","comments":true,"title":"The game of labeling","tags":["machine learning"],"tagline":"A summery of the labeing process I follow"},"excerpt":""},{"slug":"2019-01-08-nlp_retrospective","frontmatter":{"layout":"post","comments":true,"title":"Building a dialogue manager - A retrospective","tags":["deep learning","NLP"],"tagline":"Lesons learnt and thoughts after working on the dialogue management model"},"excerpt":""},{"slug":"2018-11-01-article_review_using_git","frontmatter":{"layout":"post","comments":true,"title":"Article review using git","tags":["Random thoughts"],"tagline":"Implementing a review system for articles using git"},"excerpt":""},{"slug":"2018-09-10-quantum_computing","frontmatter":{"layout":"post","comments":true,"title":"Quantum computing","tags":["Random thoughts"],"tagline":"A brief introduction to the basics of quantum computing."},"excerpt":""},{"slug":"2018-08-31-how-the-mind-works","frontmatter":{"layout":"post","comments":true,"title":"Steven Pinker's 'How the mind works'","tags":["Random thoughts"],"tagline":"A few ideas in the book I found interesting. (Though I don't fully understand or accept/agree with them all)"},"excerpt":""},{"slug":"2018-08-01-mlp_file_structure","frontmatter":{"layout":"post","comments":true,"title":"Practices I follow with the machine learning pipeline","tags":["deep learning"],"tagline":"While the ml-pipeline solves some of the problems I encounter, it doesn't solve all of them. Here I describe my process beyond the pipeline."},"excerpt":""},{"slug":"2018-07-26-ml-problems","frontmatter":{"layout":"post","comments":true,"title":"ML problems I run into","tags":["Random thoughts"],"tagline":"An ongoing list of problems I run into when using deep learning"},"excerpt":""},{"slug":"2018-07-17-tic-tac-toe","frontmatter":{"layout":"post","comments":true,"title":"Teaching a computer to play Tic-Tac-Toe.","tags":["Random thoughts"],"tagline":"A simple demonstration of teaching a computer to play tic-tac-toe. This is part of a demonstration made for the first year undergraduates."},"excerpt":""},{"slug":"2018-06-13-qubits-opened","frontmatter":{"layout":"post","comments":true,"title":"Opening of the qubits lab","tags":null},"excerpt":""},{"slug":"2018-06-11-Experiment-log","frontmatter":{"layout":"post","comments":true,"title":"Experiment log - How I keep track of my ML experiments","tags":["machine learning"],"tagline":"In order to reduce the clutter, I keep track of the experiments using a emacs org-mode."},"excerpt":""},{"slug":"2018-04-25-why-no-posting","frontmatter":{"layout":"post","comments":true,"title":"Why you no posting stuff?","tags":["Random thoughts"],"tagline":"Why indeed......"},"excerpt":""}]},"__N_SSG":true}